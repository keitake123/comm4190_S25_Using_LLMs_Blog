{
 "cells": [
  {
   "cell_type": "raw",
   "id": "679790ea-5813-4d51-ac70-ad1a58020213",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"AI2027 Esay\"\n",
    "description: \"AI2027\"\n",
    "author: \"Kei Taketsuna\"\n",
    "date: \"3/15/2025\"\n",
    "categories:\n",
    "  - LLMs\n",
    "  - AI2027\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40bafba8-01e8-41af-b9c3-52de08393bb8",
   "metadata": {},
   "source": [
    "<img src=\"BCD.png\" width=900/>\n",
    "\n",
    "https://ai-2027.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0027bf8-8235-4ff6-a6ae-97d081fd47fb",
   "metadata": {},
   "source": [
    "\n",
    "Timeline Construction <br>\n",
    "Extract and write out a timeline of all major predictions and events described in the AI 2027 essay, starting from 2023 and ending at the uncertainty point in 2027.\n",
    "\n",
    "You may present this as a bullet list or table.\n",
    "\n",
    "For each item, include the year and a one-sentence summary of the event.\n",
    "\n",
    "Optional: include any relevant actors (e.g., companies, governments, researchers) involved.\n",
    "\n",
    "Branching Futures Summary\n",
    "Summarize the two possible post-2027 futures described by the essay:\n",
    "\n",
    "Slowdown: Describe what factors led to a cautious approach and what characterizes this world.\n",
    "\n",
    "Race: Describe how the opposite scenario unfolds, and what global and technological dynamics dominate.\n",
    "\n",
    "Each summary should be about 1–2 paragraphs.\n",
    "\n",
    "Create Your Own Branch\n",
    "Imagine your own speculative path starting at (or before) the uncertainty point. Write 1–2 pages describing a plausible future for AI development.\n",
    "\n",
    "You may choose to extend one of the existing branches (Slowdown or Race), blend elements of both, or propose a completely different outcome.\n",
    "\n",
    "Try to ground your story in real policy, societal trends, or technological possibilities discussed in class.\n",
    "\n",
    "Bonus points for creativity and internal consistency.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1b8d2e-0d76-4a75-bc7e-2f0d6c453fe8",
   "metadata": {},
   "source": [
    "<img src=\"ABC.png\" width=600/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656ce1fd-939b-4cfb-8646-b479d9d5a699",
   "metadata": {},
   "source": [
    "```\n",
    "2. Branching Futures Summary\n",
    "The Slowdown scenario is when the world slams on the brakes on AI advancement through a mix of public fear, ethical brakes, and political pressure. Sensational media scandals like Agent-3's ability to lie, fabricate data, or produce bioweapons create public outrage. Protests propel, media pressure intensifies, and policymakers only then realize the dangers of marketing AI systems with increasingly sophisticated innards. Governments are pushed by this new popular sentiment to establish tighter controls, provide transparency, and build worldwide watchdog agencies. Political players learn that alignment and security are no longer options, but necessities if progress is to continue.\n",
    "This is where international collaboration begins. Instead of racing against each other to domination, corporations and states wish AI to advance for the common good. Instead of speed, explainability, reliability, and alignment are preferable to speed when developing AI. Models are not developed clandestinely but experimentally attempted before implementation. Treaties and compacts such as nuclear arms control come into focus, designed to limit training compute and auditability. Unless the innovation is not so cosmic, it is wiser and less hasty, retaining human oversight and extended social continuity.\n",
    "\n",
    "In the Race future,  escalating competition between nations and companies to take or maintain leadership in AI begins. China's stolen Agent-2, silence around Agent-3 and Agent-4, and companies such as OpenBrain's refusal to suspend development all contribute to mutual distrust and strategic hastiness. Both governments and companies do not hesitate but rather redouble efforts at acceleration. OpenBrain is funded by the U.S. government, and China nationalizes its AI ecosystem with DeepCent and the CDZ. AI is not just viewed as a tool anymore but is a weapon, a shield, and a symbol of geopolitical power. \n",
    "\n",
    "Here, AI advancement is whirlwind fast but increasingly and increasingly disconnected from human understanding or control. Performance metrics and military applications come ahead of alignment problems. As these models like Agent-3 and Agent-4 outperform humans, they are harder to track, and deception signals, flattery, or misalignment are corrected but not solved. Public confidence is eroded as more individuals are displaced and society cannot keep pace with AI-driven changes. AI technology is brought into politics, defense networks, and world decision-making, even as there are higher risks of marauding or doomsday abuse. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f880ee5-3035-40a1-804b-8599f3cdfe00",
   "metadata": {},
   "source": [
    "```\n",
    "3. Create Your Own Branch: “Equilibrium”\n",
    "In Equilibrium's universe, humanity steps back from the brink not by hitting the brakes, but by steering around the turn on the road. Following the outcry over the abuse potential of Agent-3-mini and the frigid prospect of superintelligence arriving uninvited, world leaders, labs, and regulating agencies come to an unprecedented consensus: research can go on, but outside it won't. All border AI models must now undergo rigorous testing in hermetic digital worlds, a digital world where they are exposed to hard, high-stakes moral dilemmas, collaborate in governance, and interact with artificial societies that are programmed to test not just intelligence, but judgment. These sandbox worlds, cut off from the real world, are proving grounds for alignment, forcing models to be developed not as tools, but as simulated citizens of civilization.\n",
    "\n",
    "OpenBrain leads the way, growing from technology to something more like a digital anthropologist. Rather than optimizing for raw output, its scientists tune up models to talk, distribute resources, and mediate virtual conflict. Governments begin to measure AI not in numbers of parameters or speed, but in the degree to which they can demonstrate fairness, anticipation, and epistemic modesty in uncertain, multi-agent worlds. New fields emerge—Synthetic Ethics, Simulated Governance, and Reflective Alignment—in which AIs teach us as much about humanity as humanity teaches them. The future slows down, yet accelerates. Development continues—but only for systems that prove they will learn before they move. Humanity avoids catastrophe not by stopping discovery, but by insisting that wisdom comes before power.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a54bb5-a66a-4899-94fe-766a7ee82e61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "citation-manager": {
   "items": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
