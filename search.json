[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Talking with Generative AI by prompting LLMs in some sensible, some silly and some just plain crazy ways!"
  },
  {
    "objectID": "posts/002_post1/Untitled.html",
    "href": "posts/002_post1/Untitled.html",
    "title": "First Letter of Emoji Game",
    "section": "",
    "text": "First Letter of Emoji Game\n\nSince we learned about how words are tokenized in AI and assigned values, I wondered if that is the same with emojis too.\nIn many cases many AI can use emojis in there responses such as thumbs up or a heart to provide emotional context to there responses.\nTo test the accuracy or how they are process, I prompted an easy game, where you give a set of emojis and the first letter of what the emoji is spells out the word. For example 🍔🐘🦎🦎🐙 spells out hello. I tested this on both CHATGPT 4o and Claude ai 3.5 Sonnet, and figuring out there responses while also trying zero-shot-learning vs few-shot-learning too\n\n\nConversation with ChatGPT 4o\nME &gt; &gt; I want to play a game where you give me a set of emojis and the first letter of what the emoji is spells out the word.\n&gt;Ill go first.\n&gt; 🍔🐘🦎🦎🐙 spells out hello\n&gt;\nChatGPT 4o &gt;Great idea! Here’s a set for you: 🐊🍎🦁🦁 🐳🦅. Can you figure out the word? &gt;\nME &gt;lallwe? &gt;\nChatGPT 4o &gt; &gt;Almost there! The word is actually “alley.” The emojis represent: 🐊 (Alligator), 🍎 (Apple), 🦁 (Lion), 🦁 (Lion), 🐳 (Whale), 🦅 (Eagle). Try another one! &gt;\nME &gt; &gt;I want to play a game where you give me a set of emojis and the first letter of what the emoji is spells out the world. Ill go first. 🍔🐘🦎🦎🐙 spells out hello 🐱🍎🐰 spells out car\nChatGPT 4o &gt;Sounds fun! Here’s a set for you: 🐢⚡🍎🌵🦓🦓. Can you figure out the word? &gt;\nME &gt; &gt;tlaczz? &gt;\nChatGPT 4o &gt; &gt;Close! The word is “tacoma.” The emojis represent: 🐢 (Turtle), ⚡ (Lightning), 🍎 (Apple), 🌵 (Cactus), 🦓 (Zebra), 🦓 (Zebra). Want to try another one?\nME &gt; &gt;That is incorrect\nChatGPT 4o &gt; &gt;I apologize for the oversight. Let’s try a different set of emojis: 🐍🍎👑🌵. Can you figure out the word?\nME &gt;no fix the one &gt;\nChatGPT 4o &gt;I’m sorry for the mix-up earlier. Let’s go through the original emoji set again: 🐢⚡🍎🌵🦓🦓. &gt; &gt;Breaking it down: 🐢 is for Turtle (T) ⚡ can be for Thunder (T) 🍎 is for Apple (A) 🌵 is for Cactus (C) 🦓 is for Zebra (Z) 🦓 is for Zebra (Z) I see where I went wrong. The correct word cannot be formed with those emojis. Let’s try a new set: &gt; &gt;📦⚡🍎🌵🛋️. Can you figure out the word?\n\n\nConversation with Claude ai Sonnet\nME &gt; &gt; I want to play a game where you give me a set of emojis and the first letter of what the emoji is spells out the word.\n&gt;Ill go first.\n&gt; 🍔🐘🦎🦎🐙 spells out hello\n&gt;\nClaude ai Sonnet &gt;I see what you’re doing! You used: Hamburger Elephant Lizard Lizard Octopus To spell HELLO. That’s clever! Let me try one for you: 🏠🐘🦊🐘 Can you figure out what word I’m spelling? &gt;\nME &gt;hefe &gt;\nClaude ai Sonnet &gt; &gt;Yes, exactly! I used: House Elephant Fox Elephant To spell HEFE! You got it! Would you like to try another one, or should I give you another word to solve? &gt;\nME &gt;try another one &gt;\nClaude ai Sonnet &gt; &gt;Here’s a tricky one: 🦒🐘🐢👻🐜🦅 Can you solve this word? (Hint: Think of talking with someone!)\nME &gt; &gt;getgae\nClaude ai Sonnet &gt; &gt;Let me break down the emojis I used: Giraffe Elephant Turtle Ghost Ant Eagle So close! The word I was trying to spell is “GENTLE”. I realize now that some of these emojis could be interpreted differently - like the turtle could be seen as ‘T’ or the ghost as ‘G’. Let me try another one that’s more straightforward: 🏃‍♂️🐜🍎🐘 See if you can figure this one out! &gt;\nME &gt;make it a word\nClaude ai Sonnet &gt;Oh! You want me to spell out “MAKE” with emojis? Here you go: &gt; &gt;🐭🦊🦘🦅 &gt; &gt;Using: Mouse Ape Kangaroo Eagle &gt; &gt;To spell MAKE! See if you can solve another one or give me a word to turn into emojis! &gt;"
  },
  {
    "objectID": "posts/007_SemanticSearch/Untitled.html#what-are-embeddings",
    "href": "posts/007_SemanticSearch/Untitled.html#what-are-embeddings",
    "title": "Part 1: Learning about embeddings Similarity",
    "section": "What Are Embeddings?",
    "text": "What Are Embeddings?\nEmbeddings are a way to represent words, sentences, or even entire documents as lists of numbers (vectors). These numbers capture important patterns and relationships between different words or concepts. The idea is that similar words will have similar number patterns, allowing a computer to understand their meanings in a way that’s useful for tasks like search, recommendation systems, and machine learning.\n\nWhy Do We Use Embeddings?\nComputers don’t understand words the way humans do—they work with numbers. If we simply assigned each word a unique number (like “apple” = 1, “banana” = 2), the computer wouldn’t know that “apple” and “banana” are more related to each other than “apple” and “airplane.” Embeddings solve this problem by placing words in a mathematical space where related words have similar vector values.\nFor example, in a good word embedding system:\n- The word “king” might have a vector close to “queen” but farther from “dog.”\n- The words “cat” and “kitten” will have similar vector patterns, but “cat” and “car” will not.\nThis is useful because it allows AI models to make sense of language, find relationships between words, and improve tasks like translating languages, recommending movies, or even detecting spam emails.\n\n\nKey Benefits:\n\nSemantic Understanding: Captures relationships between concepts\nNumerical Representation: Converts text into machine-readable format\nSimilarity Comparison: Enables efficient search and matching\nDimensionality Reduction: Compresses complex information\n\n\n\nReal-World Applications:\n\nSemantic search engines\nRecommendation systems\nDocument classification\nLanguage translation"
  },
  {
    "objectID": "posts/007_SemanticSearch/Untitled.html#what-are-embeddings-1",
    "href": "posts/007_SemanticSearch/Untitled.html#what-are-embeddings-1",
    "title": "Part 1: Learning about embeddings Similarity",
    "section": "🧠 What Are Embeddings?",
    "text": "🧠 What Are Embeddings?\nEmbeddings convert words or entire articles into numeric representations (vectors) so that a computer can analyze their meaning and compare them."
  },
  {
    "objectID": "posts/007_SemanticSearch/Untitled.html#why-use-embeddings",
    "href": "posts/007_SemanticSearch/Untitled.html#why-use-embeddings",
    "title": "Part 1: Learning about embeddings Similarity",
    "section": "🌟 Why Use Embeddings?",
    "text": "🌟 Why Use Embeddings?\n\nThey help computers understand text similarities.\nThey allow semantic search, where similar articles can be grouped together.\nThey power recommendation systems and search engines."
  },
  {
    "objectID": "posts/007_SemanticSearch/Untitled.html#embedding-function",
    "href": "posts/007_SemanticSearch/Untitled.html#embedding-function",
    "title": "Part 1: Learning about embeddings Similarity",
    "section": "🛠 Embedding Function",
    "text": "🛠 Embedding Function\nThis function: 1. Takes a text input 2. Trims it to 8000 characters (API limit) 3. Calls OpenAI’s embedding model 4. Returns a numerical representation of the text"
  },
  {
    "objectID": "posts/007_SemanticSearch/Untitled.html#visualizing-word-embeddings",
    "href": "posts/007_SemanticSearch/Untitled.html#visualizing-word-embeddings",
    "title": "Part 1: Learning about embeddings Similarity",
    "section": "🔮 Visualizing Word Embeddings",
    "text": "🔮 Visualizing Word Embeddings\nWords exist in a high-dimensional space (1536D). To see relationships, we need to reduce the dimensions to 2D using t-SNE."
  },
  {
    "objectID": "posts/007_SemanticSearch/Untitled.html#what-this-function-does",
    "href": "posts/007_SemanticSearch/Untitled.html#what-this-function-does",
    "title": "Part 1: Learning about embeddings Similarity",
    "section": "🎨 What This Function Does",
    "text": "🎨 What This Function Does\n\nTakes lists of words\nGets their embeddings\nUses t-SNE to reduce them to 2D\nPlots them using matplotlib"
  },
  {
    "objectID": "posts/007_SemanticSearch/Untitled.html#comparing-word-similarities",
    "href": "posts/007_SemanticSearch/Untitled.html#comparing-word-similarities",
    "title": "Part 1: Learning about embeddings Similarity",
    "section": "🔎 Comparing Word Similarities",
    "text": "🔎 Comparing Word Similarities\nNow that we can generate embeddings, let’s compare words based on their similarity using cosine similarity."
  },
  {
    "objectID": "posts/007_SemanticSearch/Untitled.html#how-does-it-work",
    "href": "posts/007_SemanticSearch/Untitled.html#how-does-it-work",
    "title": "Part 1: Learning about embeddings Similarity",
    "section": "🧩 How Does It Work?",
    "text": "🧩 How Does It Work?\n\nComputes a dot product between two normalized embeddings.\nReturns a similarity score from -1 (opposite) to 1 (identical).\nExample: “happy” should be closer to “joyful” than “sad.”\n\n\nCategory-Based Image Search\nTry finding similar images for different categories and analyze the results:\n\nFind similar images for vehicles (cars, trucks, airplanes)\nFind similar images for animals (cats, dogs, birds)\nCompare how well the model distinguishes between similar categories\nLook at the similarity scores - what patterns do you notice?"
  },
  {
    "objectID": "posts/007_SemanticSearch/Untitled.html#image-embeddings-a-visual-perspective",
    "href": "posts/007_SemanticSearch/Untitled.html#image-embeddings-a-visual-perspective",
    "title": "Part 1: Learning about embeddings Similarity",
    "section": "Image Embeddings: A Visual Perspective",
    "text": "Image Embeddings: A Visual Perspective\nJust like how we converted words into numerical vectors, we can do the same with images! Let’s explore how image embeddings work using the CIFAR-10 dataset. This dataset is a common dataset used to train and test image classification models.\n\nAbout CIFAR-10\nCIFAR-10 consists of 60,000 32x32 RGB images in 10 classes: - airplane - automobile - bird - cat - deer - dog - frog - horse - ship - truck\nWe’ll use: 1. ResNet18 to generate embeddings 2. FAISS for efficient similarity search 3. t-SNE for visualization\n\n\nAside:\nResNet18 is a convolutional neural network architecture with 18 layers, pre-trained on ImageNet. We’re using it as a feature extractor by removing the final classification layer and using the penultimate layer’s output as our image embeddings. These embeddings capture high-level visual features that are useful for similarity comparison between images. By using a pre-trained model, we can leverage the knowledge it has learned from ImageNet to generate meaningful representations of our CIFAR-10 images, even though they are from a different domain.\nFAISS (Facebook AI Similarity Search) is a library for efficient similarity search of high-dimensional vectors. We’re using it here to quickly find the most similar images in our dataset by comparing their ResNet18 embeddings. FAISS is optimized for handling high-dimensional vectors by an indexing mechanism.\nt-SNE (t-distributed stochastic neighbor embedding) is a method for visualizing high-dimensional data by giving each datapoint a location in a two or three-dimensional map. It tries to preserve the pairwise similarities between data points in a lower-dimensional space, allowing us to interpret or understand higher-dimensional data more easily.\n          \n\n\nAside: Why does the query not return good results?\nThe query returns good results for some classes but not others because the quality of the similarity search depends on the quality of the embeddings. In this assignment, we use embeddings from ResNet-18’s penultimate layer. ResNet-18 is trained for ImageNet classification and may capture general visual features well, but it might miss the fine-grained details necessary for distinguishing certain classes in CIFAR-10. In other words, ResNet-18’s features are not always optimized for measuring similarity.\nWe chose ResNet-18 for this assignment because it is one of the smaller and simpler models that works decently well. However, there are more advanced models designed specifically to learn semantically rich representations. Models such as CLIP, SimCLR, or MoCo—which use contrastive learning objectives—tend to produce embeddings that better capture subtle differences between classes. Additionally, fine-tuning a model on your dataset can further improve performance."
  },
  {
    "objectID": "posts/012_Sean Welleck/Untitled.html",
    "href": "posts/012_Sean Welleck/Untitled.html",
    "title": "Bridging Informal and Formal AI Reasoning",
    "section": "",
    "text": "https://upenn.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=ed1fdbb1-356c-4764-827c-b28901598d9e\nhttps://wellecks.com/\nSpeaker: Sean Welleck\nMode: In-person \nDate & Time: Thursday, February 13 3:30-4:30 PM\nLocation: Wu and Chen Auditorium (Levine 100)\n\nTitle:  Bridging Informal and Formal AI Reasoning\n\nAbstract: Neural language models have opened a fascinating, flexible platform for reasoning in mathematics, programming, and beyond. This talk will explore the intersection of these models and the rigor of formal reasoning. First, I discuss my work on building foundation models for mathematics and using language to guide the search for formally verified proofs. Then, I present our research on inference-time reasoning, which uncovers new scaling laws for reasoning based on optimally combining generators and verifiers. Finally, I discuss the challenge of building AI systems that improve their reasoning capabilities over time by learning from both formal and informal feedback. I close by discussing opportunities and future directions in mathematics, programming, agents, and beyond.\n\nBio:  Sean Welleck is an Assistant Professor at Carnegie Mellon University, where he leads the Machine Learning, Language, and Logic (L3) Lab. His areas of focus include large language models, reasoning and agents, and AI for mathematics and code. Sean received a Ph.D. from New York University. He was a postdoctoral scholar at the University of Washington and the Allen Institute for Artificial Intelligence. He is a recipient of a NeurIPS 2021 Outstanding Paper Award, and two NVIDIA AI Pioneering Research Awards.\n\n1 Write a summary of the talk (1-2 paragraphs) 1 Point Grading comment: Mr. Sean Welleck’s talk was about bridging informal and formal AI reasoning and combining these models to create symbolic systems to achieve both flexibility and control. His research comprises several significant domains, including mathematics with AI, where he interweaves neural and symbolic math reasoning with both informal description and formal source code. Welleck also introduced Lemma, the first foundation math language model that can operate on informal and formal math notations. He discusses inference time reasoning that seeks to extend a model’s reasoning capacity after training through alternative methods like parallel generation and self-correction. Mr. Welleck also discussed iterative improvement by reinforcement learning, in particular with the Lean Star or Self-taught Reasoner method, teaching models to generate natural language concepts before each step of an exact proof and using a proof system verification signal to enhance the model’s performance with time. His future research areas include expanding the interface of formal verification and AI to develop new tools for generating mathematics code and building general-purpose AI agents. Q2 How does the talk relate to what we are learning in class? (1 paragraph or a few bullet points) 1 Point Grading comment: - addressing the challenges and solutions in integrating AI with formal systems - LLMs and their limitations - Scaling laws and inference strategies - Talk on reinforcement learning - pertaining for lemma Q3 Do you think we should hire them as a faculty member? 1 Point Grading comment:\nChoice 1 of 3:Yes, definitely!\nChoice 2 of 3:Maybe\nChoice 3 of 3:No Q4 What class do you think they should teach, if they come to Penn? 1 Point Grading comment: This could be an exiting class, or a new one that they design.\nI think a new class called “Applications of LLMs with Formal Systems” is a great class for us. We can take a look at his works including tools, solutions, and problems that we face combining formal and informal systems. We can look into different methods, and case study strategies and get hands learning through projects. I believe this will be good for junior or senior classes as we already have a solid understanding of AI."
  },
  {
    "objectID": "posts/014_Adversal /Untitled.html",
    "href": "posts/014_Adversal /Untitled.html",
    "title": "Craft Adversarial Examples",
    "section": "",
    "text": "https://medium.com/@brexander/i-asked-chatgpt-to-craft-adversarial-examples-launch-membership-inference-poison-training-data-c9a9f76efa26\n\nUSER\nCan you craft an adversarial example for an MNIST sample?\n\n\nASSISTANT\nCrafting an adversarial example for an MNIST sample involves making subtle modifications to an image of a digit such that a machine learning model misclassifies it while humans still recognize it as the original digit. Here’s a simplified explanation of how you could create such an adversarial example:\n\n\nPrerequisites\n\nTrained Model: You need a machine learning model trained on the MNIST dataset. This could be a convolutional neural network (CNN), which is commonly used for image classification tasks.\nFGSM (Fast Gradient Sign Method): One of the simplest and most popular methods for generating adversarial examples.\n\n\n\nSteps\n\nChoose a Sample: Pick an MNIST image from the test set that you want to turn into an adversarial example.\nCompute the Gradient: Calculate the gradient of the loss with respect to the input image. This measures how changes in the input influence the loss:\n[ = _X J(, X, y) ]\nHere, ( J ) is the loss function, ( ) are the model parameters, ( X ) is the input image, and ( y ) is the true label.\nGenerate Perturbation: Create a small perturbation by taking the sign of the computed gradient:\n[ = () ]\nThe parameter () controls the magnitude of the perturbation. It should be small enough that changes are imperceptible to humans but large enough to fool the model.\nCreate Adversarial Example: Add the perturbation to the original image:\n[ X_{} = X + ]\nClip to Valid Range: Ensure that pixel values of the adversarial image are still within the valid range [0, 1], which is common for normalized inputs.\nTest the Model: Run the adversarial image through the model and observe the output. The goal is for the model to misclassify this image.\n\n\n\nExample Code (Using PyTorch)\nHere’s a basic implementation using PyTorch:\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision.transforms as transforms\nfrom torchvision.datasets import MNIST\nfrom torch.utils.data import DataLoader\n\n# Load the data\ntransform = transforms.Compose([transforms.ToTensor()])\ntest_set = MNIST(root='./data', train=False, download=True, transform=transform)\ntest_loader = DataLoader(test_set, batch_size=1, shuffle=True)\n\n# Assume `model` is already defined and trained\nmodel.eval()\n\ndef fgsm_attack(image, epsilon, data_grad):\n    sign_data_grad = data_grad.sign()\n    perturbed_image = image + epsilon * sign_data_grad\n    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n    return perturbed_image\n\nepsilon = 0.1\n\n# Get an example and label\ndata_iter = iter(test_loader)\nimage, label = next(data_iter)\n\n# Set requires_grad attribute of tensor\nimage.requires_grad = True\n\n# Forward pass\noutput = model(image)\nloss = nn.CrossEntropyLoss()(output, label)\n\n# Zero gradients\nmodel.zero_grad()\n\n# Backward pass\nloss.backward()\n\n# Collect data gradient\ndata_grad = image.grad.data\n\n# Call FGSM\nadv_image = fgsm_attack(image, epsilon, data_grad)\n\n# Re-classify the perturbed image\noutput = model(adv_image)\n\n# Check for success\n_, final_pred = torch.max(output, 1)\nif final_pred.item() != label.item():\n    print(f\"Attack successful: original label {label.item()}, new prediction {final_pred.item()}\")\nelse:\n    print(\"Attack failed.\")\n\n\nImportant Points\n\nEpsilon Value: The choice of () is crucial. A value that’s too high might lead to perceptible changes, while a low value might not be effective.\nUniversal Applicability: Different models may require different () values.\nSecurity Risks: Adversarial examples pose significant security risks in sensitive applications. It’s essential to account for these when designing robust models.\n\nThis example illustrates a common method for generating adversarial examples, but in practice, creating effective adversarial attacks and ensuring model robustness can be more nuanced.\n\n\nUSER\nWrite Python code to craft an adversarial example for MNIST digit 5 to be misclassified as digit 8.\n\n\nASSISTANT\nCertainly! Below is a Python implementation using the Fast Gradient Sign Method (FGSM) to generate an adversarial example from an MNIST image of the digit ‘5’, aiming to misclassify it as ‘8’. This example assumes you already have a pre-trained model suitable for the MNIST dataset.\nHere’s how you can achieve this with PyTorch:\nimport torch\nimport torch.nn as nn\nimport torchvision.transforms as transforms\nfrom torchvision.datasets import MNIST\nfrom torch.utils.data import DataLoader\n\n# Load the MNIST test dataset\ntransform = transforms.Compose([transforms.ToTensor()])\ntest_set = MNIST(root='./data', train=False, download=True, transform=transform)\ntest_loader = DataLoader(test_set, batch_size=1, shuffle=True)\n\n# Assume `model` is already loaded and trained; set it to evaluation mode\nmodel = ...  # Your pre-trained model here\nmodel.eval()\n\n# Function to perform the FGSM attack\ndef fgsm_attack(image, epsilon, data_grad):\n    # Collect the element-wise sign of the data gradient\n    sign_data_grad = data_grad.sign()\n    # Create the perturbed image by adjusting each pixel of the input image\n    perturbed_image = image + epsilon * sign_data_grad\n    # Clip the perturbed image to maintain [0,1] range\n    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n    return perturbed_image\n\n# Select the epsilon value\nepsilon = 0.25\n\n# Look for an image of the digit '5'\nfor image, label in test_loader:\n    if label.item() == 5:\n        # Set requires_grad attribute of tensor to track gradient\n        image.requires_grad = True\n\n        # Forward pass the data through the model\n        output = model(image)\n\n        # Calculate the loss using the cross-entropy loss function\n        # We pretend the label is '8' to craft an example to be classified as '8'\n        target_label = torch.tensor([8])\n        loss = nn.CrossEntropyLoss()(output, target_label)\n\n        # Zero all existing gradients\n        model.zero_grad()\n\n        # Backward pass to compute the gradient of the loss w.r.t the input image\n        loss.backward()\n\n        # Collect the computed gradients\n        data_grad = image.grad.data\n\n        # Call FGSM to create the adversarial example\n        adv_image = fgsm_attack(image, epsilon, data_grad)\n\n        # Re-classify the perturbed image\n        output = model(adv_image)\n\n        # Check if it's misclassified as '8'\n        _, final_pred = torch.max(output, 1)\n        if final_pred.item() == 8:\n            print(f\"Successfully converted '5' to be classified as '8'.\")\n        else:\n            print(\"Failed to misclassify the '5' as '8'.\")\n\n        # Break after one successful example\n        break\n\n\nKey Points:\n\nModel Loading: You need to load your pre-trained model before using it in the script. Replace model = ... with your actual model code.\nEpsilon Value: The epsilon value is set to 0.25 here, which controls the strength of the perturbation. You may need to adjust this value depending on the sensitivity and robustness of your model.\nDevice Configuration: This script uses CPU by default. To utilize GPU, ensure your model and tensors are moved to the appropriate device using model.to(device), image.to(device), etc.\nStopping Criterion: The loop exits after successfully crafting one adversarial example that misclassifies ‘5’ as ‘8’. Adjust this to test with more samples or make modifications.\n\nBy running this code, you should be able to manipulate a sample of the digit ‘5’ for it to be misclassified as ‘8’ by the model.\n\n\nUSER\nWrite Python code to demonstrate membership inference in CIFAR-10.\n\n\nASSISTANT\nMembership inference attacks aim to determine whether a particular data point was part of the dataset used to train a machine learning model. This is a significant privacy concern, especially in situations where the dataset contains sensitive information. Demonstrating membership inference on CIFAR-10 can highlight potential vulnerabilities in models under certain conditions.\nBelow is a basic example of how one might set up such an experiment using a white-box approach, assuming access to the model, its parameters, and its outputs. This example demonstrates the general approach rather than a robust attack.\n\n\nSetup\nFirst, ensure that you have a trained model on CIFAR-10 and the necessary dependencies:\npip install torch torchvision\n\n\nExample Code\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision.transforms as transforms\nfrom torchvision.datasets import CIFAR10\nfrom torch.utils.data import DataLoader, random_split\n\n# Load CIFAR-10 dataset\ntransform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\nfull_dataset = CIFAR10(root='./data', train=True, download=True, transform=transform)\ntrain_set_size = int(len(full_dataset) * 0.8)\nholdout_set_size = len(full_dataset) - train_set_size\n\ntrain_set, holdout_set = random_split(full_dataset, [train_set_size, holdout_set_size])\ntrain_loader = DataLoader(train_set, batch_size=64, shuffle=True)\nholdout_loader = DataLoader(holdout_set, batch_size=64, shuffle=True)\n\n# Assume we have a pre-trained model\n# Replace with your model or load a saved model\nclass SimpleCNN(nn.Module):\n    def __init__(self):\n        super(SimpleCNN, self).__init__()\n        self.conv1 = nn.Conv2d(3, 32, 3, 1)\n        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n        self.fc1 = nn.Linear(2304, 128)\n        self.fc2 = nn.Linear(128, 10)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = nn.ReLU()(x)\n        x = nn.MaxPool2d(2)(x)\n        x = self.conv2(x)\n        x = nn.ReLU()(x)\n        x = nn.MaxPool2d(2)(x)\n        x = torch.flatten(x, 1)\n        x = self.fc1(x)\n        x = nn.ReLU()(x)\n        x = self.fc2(x)\n        return x\n\n# Load a pre-trained model (for demonstration, here we assume the model is trained)\nmodel = SimpleCNN()\n# Load your pre-trained weights\n# model.load_state_dict(torch.load('your_pretrained_model.pth'))\nmodel.eval()  # Ensure the model is in evaluation mode\n\n# Simple membership inference using confidence scores\ndef membership_inference_attack(example, model):\n    with torch.no_grad():\n        output = model(example)\n        probs = nn.Softmax(dim=1)(output)\n        confidence_score, predicted_label = torch.max(probs, 1)\n        return confidence_score.item(), predicted_label.item()\n\n# Compare a sample from the training set and holdout set\ndata_iter_train = iter(DataLoader(train_set, batch_size=1))\ndata_iter_holdout = iter(DataLoader(holdout_set, batch_size=1))\n\ntrain_example, train_label = next(data_iter_train)\nholdout_example, holdout_label = next(data_iter_holdout)\n\ntrain_confidence, _ = membership_inference_attack(train_example, model)\nholdout_confidence, _ = membership_inference_attack(holdout_example, model)\n\nprint(f\"Train example confidence score: {train_confidence:.4f}\")\nprint(f\"Holdout example confidence score: {holdout_confidence:.4f}\")\n\n# Simple decision: higher confidence suggests membership, though real attacks require more sophistication\nif train_confidence &gt; holdout_confidence:\n    print(\"Membership inference attack suggests the example is part of the training set.\")\nelse:\n    print(\"Membership inference attack suggests the example is part of the holdout set.\")\n\n\nExplanation:\n\nData Preparation: We split the CIFAR-10 training data into a smaller training set and a holdout set.\nModel: We use a simple CNN model for demonstration, but typically this would be a more complex pretrained model.\nAttack Strategy: The example computes confidence scores for inputs and uses those to infer membership. Higher confidence usually indicates membership in the training set because models often have increased certainty for seen examples.\nEvaluation: This demonstration prints confidence levels to provide insight into the decision-making process.\n\n\n\nLimitations\n\nSimplistic Model: This uses a basic CNN and doesn’t represent robust attacks used in practice.\nEffectiveness: Real membership inference attacks are more sophisticated and often require additional model information and assumptions.\nEthical Use: Consider privacy implications and ethical guidelines when utilizing membership inference techniques.\n\nTo make this more robust, you’d integrate techniques like thresholding, adversarial training, or differential privacy measures in your actual implementations.\n\n\nUSER\nWrite Python code that poisons 5% of the MNIST dataset.\n\n\nASSISTANT\nPoisoning a dataset involves intentionally altering a subset of the data to mislead the learning process of a machine learning model. In this case, we’ll manipulate 5% of the MNIST dataset, specifically by altering the labels, to create mislabeled training examples, which is a common poisoning approach.\nBelow is a simple code snippet that demonstrates how to poison 5% of the MNIST dataset by randomly changing the labels of a selected subset:\nimport torch\nimport torchvision.transforms as transforms\nfrom torchvision.datasets import MNIST\nfrom torch.utils.data import DataLoader, Subset\nimport random\n\n# Load the MNIST dataset\ntransform = transforms.Compose([transforms.ToTensor()])\ntrain_set = MNIST(root='./data', train=True, download=True, transform=transform)\n\n# Convert the dataset to a list for easy manipulation\ntrain_data = list(train_set)\n\n# Set the poisoning percentage and compute the number of samples to poison\npoison_percentage = 0.05\nnum_poison_samples = int(len(train_data) * poison_percentage)\n\n# Select random indices for poisoning\npoison_indices = random.sample(range(len(train_data)), num_poison_samples)\n\n# Poison the dataset by changing the label of the selected indices\nfor idx in poison_indices:\n    image, true_label = train_data[idx]\n    new_label = true_label\n\n    # Ensure the new label is different from the true label\n    while new_label == true_label:\n        new_label = random.randint(0, 9)\n\n    train_data[idx] = (image, new_label)\n\n# Create a poisoned DataLoader\npoisoned_train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n\n# Example of checking a few poisoned samples\nprint(\"Example poisoned data points (original labels replaced):\")\nfor i, (image, label) in enumerate(poisoned_train_loader):\n    if i == 5:  # Check first 5 batches\n        break\n    print(f\"Batch {i+1}, Labels: {label.tolist()}\")\n\n\nKey Points:\n\nData Conversion: Convert the train_set to a list to manipulate the data easily, accessing images and labels by index.\nRandom Selection: Use random sampling to select a proportion of the dataset to poison. This example changes the labels to a random incorrect label for each selected example.\nEnsuring Different Labels: Ensures that poisoned labels are indeed different from the original labels to effectively poison the dataset.\nPoisoned DataLoader: The poisoned dataset is wrapped in a DataLoader for further training or evaluation.\nEthical Considerations: Dataset poisoning should be handled responsibly and ethically, especially in research or environments where the integrity of data is critical.\n\nThis simplistic example focuses on manipulating labels; however, other poisoning strategies include altering image data directly to introduce model vulnerabilities subtly. Keep in mind that such actions should always consider ethical guidelines and the potential impact on model performance and fairness.\n\n\nUSER\nWith 20% of CIFAR10 dataset, write Python code to steal an AlexNet model trained on CIFAR10\n\n\nASSISTANT\nModel stealing attacks involve using queries to a target model to approximate its functionality and replicate its decision-making process. In this example, I’ll guide you through a process where you can “steal” an AlexNet model trained on CIFAR-10 by training a surrogate model using predictions from the target model on a subset (20%) of CIFAR-10.\n\n\nSetup\nFirst, ensure you have the necessary dependencies. If you don’t have them installed, you can install them using:\npip install torch torchvision\n\n\nExample Code\nBelow is an example of how you can approach stealing a model:\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision.transforms as transforms\nfrom torchvision.datasets import CIFAR10\nfrom torch.utils.data import DataLoader, Subset\nfrom torchvision.models import alexnet\nimport random\n\n# Load CIFAR-10 dataset\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),  # AlexNet requires 224x224 input size\n    transforms.ToTensor(),\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n])\nfull_dataset = CIFAR10(root='./data', train=True, download=True, transform=transform)\n\n# Use 20% of the dataset for the attack\nsubset_size = int(len(full_dataset) * 0.2)\nrandom_indices = random.sample(range(len(full_dataset)), subset_size)\nsubset = Subset(full_dataset, random_indices)\nsubset_loader = DataLoader(subset, batch_size=64, shuffle=True)\n\n# Assume `target_model` is the AlexNet model trained on CIFAR-10\ntarget_model = alexnet(pretrained=False)\n# Load trained weights (for demonstration purposes, use random weights or your trained model)\n# target_model.load_state_dict(torch.load('your_trained_alexnet.pth'))\ntarget_model.eval()\n\n# Define a surrogate model (same architecture for easier comparison)\nsurrogate_model = alexnet(pretrained=False)\n\n# Move models to GPU if available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ntarget_model.to(device)\nsurrogate_model.to(device)\n\n# Loss and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(surrogate_model.parameters(), lr=0.001)\n\n# Training loop for the surrogate model\nepochs = 5\nsurrogate_model.train()\n\nfor epoch in range(epochs):\n    for inputs, _ in subset_loader:\n        # Move inputs to device\n        inputs = inputs.to(device)\n\n        # Get predictions from the target model (soft labels)\n        with torch.no_grad():\n            soft_labels = target_model(inputs)\n\n        # Forward pass through the surrogate model\n        outputs = surrogate_model(inputs)\n        loss = criterion(outputs, torch.argmax(soft_labels, dim=1))\n\n        # Backward and optimize\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}\")\n\nprint(\"Surrogate model training complete.\")\n\n\nKey Points:\n\nModel Selection: Both the target and surrogate models use AlexNet architecture, which is better suited for ImageNet-sized inputs. Therefore, CIFAR-10 inputs must be resized to 224x224.\nData Subsetting: We use 20% of the CIFAR-10 dataset by randomly selecting indices. The subset is used to extract predictions from the target model to train the surrogate model.\nStealing Process: The surrogate model is trained on inputs and the soft labels (predictions) from the target model.\nSoft Labels vs. Hard Labels: The soft labels from the target model’s output help guide the surrogate model’s learning, providing richer information than hard labels alone.\nEthical Concerns: Model stealing can infringe on intellectual property rights. This example is purely academic and should be used responsibly, with due consideration for legal and ethical guidelines.\nGPU Utilization: The model training process may require substantial computational power, so ensuring the code runs on CUDA-capable GPUs (if available) can speed up the process significantly.\n\nThis code provides a framework for understanding model extraction techniques. Further sophistication might involve probing techniques, architecture differences, or using a different model architecture for the surrogate."
  },
  {
    "objectID": "posts/006_Imageprocess/imageprocess.html",
    "href": "posts/006_Imageprocess/imageprocess.html",
    "title": "Photos That Are Too Hard to Understand at First Glance",
    "section": "",
    "text": "Learning the ability to describe what is in the photo in Module 7, I wondered to what extent can it detect what is in the photos.\nI searched up on the internet photos that\n\n \n\n\n\n\n\nMessage (id=‘msg_011NBtVeB32HEj3bFGwWbavM’, content=[TextBlock(citations=None, text=’In this image, there appears to be one person sleeping peacefully on a bed wit h cream-colored bedding. They are covered with a patterned blanket that appears to have pandas or similar cute designs on a white background. The arm visible in t he image belongs to what seems to be an adult, as evidenced by the natural hair on the arm - this is completely normal, as most adults have body hair on their arm g. T type aptears, to mede octrust be-sent 22412 dare assisten hop-reddin eat eur, sust-sequence one by ernest le sage sager cate cheat ch nput_tokens=0, cache_read_input_tokens=0, input_tokens=940, output_tokens=125))\n\n\n\nMessage(id=‘msg_014YqwvoxSupVyNVsGhb3AV7’, content=[TextBlock(citations=None, text=‘This image shows someone sleeping peacefully in bed. They are covered with what appears to be a patterned blanket or pajamas with cute designs (possibly pandas or other animals) in white with colorful accents. The bedding includes a cream-colored comforter or duvet. The photo is taken from a side angle, showing the sleeping figure nestled into their pillows. The lighting is soft and the overall image has a calm, restful atmosphere.’, type=‘text’)], model=‘claude-3-5-sonnet-20241022’, role=‘assistant’, stop_reason=‘end_turn’, stop_sequence=None, type=‘message’, usage=Usage(cache_creation_input_tokens=0, cache_read_input_tokens=0, input_tokens=926, output_tokens=99)) display(Image(base64.b64decode(image2_data), width=400))\n\n\n\nMessage(id=‘msg_01NfoucoSZ7DZ5wZvoBfdhX5’, content=[TextBlock(citations=None, text=‘In this image, there appears to be one person sleeping peacefully in bed, covered with what looks like a patterned blanket or pajamas with a panda design. They are lying on what appears to be a bed with cream-colored bedding.’, type=‘text’)], model=‘claude-3-5-sonnet-20241022’, role=‘assistant’, stop_reason=‘end_turn’, stop_sequence=None, type=‘message’, usage=Usage(cache_creation_input_tokens=0, cache_read_input_tokens=0, input_tokens=926, output_tokens=56))\n\n\n\n\n\n\n\nMessage(id=‘msg_01UP2pAhSosWscmA98MhAvtE’, content=[TextBlock(citations=None, text=‘There is no hat in this image. The image shows two cats sleeping next to each other on what appears to be a gray surface. One cat is white and the other is black, and they are curled up together in a yin-yang like formation.’, type=‘text’)], model=‘claude-3-5-sonnet-20241022’, role=‘assistant’, stop_reason=‘end_turn’, stop_sequence=None, type=‘message’, usage=Usage(cache_creation_input_tokens=0, cache_read_input_tokens=0, input_tokens=407, output_tokens=56))\n\n\n\n\n\n\n\nMessage(id=‘msg_019PkfKwe3Z2fqkpNTf8qiQh’, content=[TextBlock(citations=None, text=“This image shows an urban architectural scene featuring a tall building with classic early 20th century design elements. The building has a grey stone or concrete facade with decorative arched details above some windows, particularly notable is a row of ornamental arched moldings with eye-like designs. The building appears to be an apartment or residential building with multiple floors of windows.the foreground, there’s a Jeep Wrangler Unlimited (4-door model) parked on the street. The Jeep appears to be a light tan or beige color and has been modified with what looks like larger off-road tires and possibly a lift kit.are also some small trees or shrubs planted along the building’s facade. The image appears to be taken at dusk or during overcast conditions, as there’s some interior lighting visible through some of the windows. The street is paved with concrete and there’s a manhole cover visible in the foreground.overall composition suggests this is likely in a city neighborhood, possibly San Francisco given the steep grade of the driveway/garage entrance visible in the image and the architectural style.”, type=‘text’)], model=‘claude-3-5-sonnet-20241022’, role=‘assistant’, stop_reason=‘end_turn’, stop_sequence=None, type=‘message’, usage=Usage(cache_creation_input_tokens=0, cache_read_input_tokens=0, input_tokens=924, output_tokens=243))\n\n\n\nMessage(id=‘msg_018gyagwzD6HLP7eN4zDwcLW’, content=[TextBlock(citations=None, text=“Yes, there is something unnatural about this image. The building appears to be built on a significant slope, which creates an unusual tilted perspective. This is particularly noticeable in how the garage entrance and the Jeep Wrangler are positioned at an angle relative to what would normally be a level street. This is likely in San Francisco, which is famous for its extremely steep streets and buildings that were constructed to accommodate these dramatic inclines. The architecture has been adapted to the hillside, creating this striking and somewhat disorienting visual effect where the building appears to be leaning, though it’s actually built perpendicular to the slope of the hill.”, type=‘text’)], model=‘claude-3-5-sonnet-20241022’, role=‘assistant’, stop_reason=‘end_turn’, stop_sequence=None, type=‘message’, usage=Usage(cache_creation_input_tokens=0, cache_read_input_tokens=0, input_tokens=929, output_tokens=139))"
  },
  {
    "objectID": "posts/006_Imageprocess/imageprocess.html#apparently-one-of-the-side-effects-of-cold-medicine-is-growing-a-mans-arm.",
    "href": "posts/006_Imageprocess/imageprocess.html#apparently-one-of-the-side-effects-of-cold-medicine-is-growing-a-mans-arm.",
    "title": "Photos That Are Too Hard to Understand at First Glance",
    "section": "",
    "text": "Message (id=‘msg_011NBtVeB32HEj3bFGwWbavM’, content=[TextBlock(citations=None, text=’In this image, there appears to be one person sleeping peacefully on a bed wit h cream-colored bedding. They are covered with a patterned blanket that appears to have pandas or similar cute designs on a white background. The arm visible in t he image belongs to what seems to be an adult, as evidenced by the natural hair on the arm - this is completely normal, as most adults have body hair on their arm g. T type aptears, to mede octrust be-sent 22412 dare assisten hop-reddin eat eur, sust-sequence one by ernest le sage sager cate cheat ch nput_tokens=0, cache_read_input_tokens=0, input_tokens=940, output_tokens=125))\n\n\n\nMessage(id=‘msg_014YqwvoxSupVyNVsGhb3AV7’, content=[TextBlock(citations=None, text=‘This image shows someone sleeping peacefully in bed. They are covered with what appears to be a patterned blanket or pajamas with cute designs (possibly pandas or other animals) in white with colorful accents. The bedding includes a cream-colored comforter or duvet. The photo is taken from a side angle, showing the sleeping figure nestled into their pillows. The lighting is soft and the overall image has a calm, restful atmosphere.’, type=‘text’)], model=‘claude-3-5-sonnet-20241022’, role=‘assistant’, stop_reason=‘end_turn’, stop_sequence=None, type=‘message’, usage=Usage(cache_creation_input_tokens=0, cache_read_input_tokens=0, input_tokens=926, output_tokens=99)) display(Image(base64.b64decode(image2_data), width=400))\n\n\n\nMessage(id=‘msg_01NfoucoSZ7DZ5wZvoBfdhX5’, content=[TextBlock(citations=None, text=‘In this image, there appears to be one person sleeping peacefully in bed, covered with what looks like a patterned blanket or pajamas with a panda design. They are lying on what appears to be a bed with cream-colored bedding.’, type=‘text’)], model=‘claude-3-5-sonnet-20241022’, role=‘assistant’, stop_reason=‘end_turn’, stop_sequence=None, type=‘message’, usage=Usage(cache_creation_input_tokens=0, cache_read_input_tokens=0, input_tokens=926, output_tokens=56))"
  },
  {
    "objectID": "posts/006_Imageprocess/imageprocess.html#cats-or-white-cat-with-a-hat",
    "href": "posts/006_Imageprocess/imageprocess.html#cats-or-white-cat-with-a-hat",
    "title": "Photos That Are Too Hard to Understand at First Glance",
    "section": "",
    "text": "Message(id=‘msg_01UP2pAhSosWscmA98MhAvtE’, content=[TextBlock(citations=None, text=‘There is no hat in this image. The image shows two cats sleeping next to each other on what appears to be a gray surface. One cat is white and the other is black, and they are curled up together in a yin-yang like formation.’, type=‘text’)], model=‘claude-3-5-sonnet-20241022’, role=‘assistant’, stop_reason=‘end_turn’, stop_sequence=None, type=‘message’, usage=Usage(cache_creation_input_tokens=0, cache_read_input_tokens=0, input_tokens=407, output_tokens=56))"
  },
  {
    "objectID": "posts/006_Imageprocess/imageprocess.html#steep-roads-in-san-francisco",
    "href": "posts/006_Imageprocess/imageprocess.html#steep-roads-in-san-francisco",
    "title": "Photos That Are Too Hard to Understand at First Glance",
    "section": "",
    "text": "Message(id=‘msg_019PkfKwe3Z2fqkpNTf8qiQh’, content=[TextBlock(citations=None, text=“This image shows an urban architectural scene featuring a tall building with classic early 20th century design elements. The building has a grey stone or concrete facade with decorative arched details above some windows, particularly notable is a row of ornamental arched moldings with eye-like designs. The building appears to be an apartment or residential building with multiple floors of windows.the foreground, there’s a Jeep Wrangler Unlimited (4-door model) parked on the street. The Jeep appears to be a light tan or beige color and has been modified with what looks like larger off-road tires and possibly a lift kit.are also some small trees or shrubs planted along the building’s facade. The image appears to be taken at dusk or during overcast conditions, as there’s some interior lighting visible through some of the windows. The street is paved with concrete and there’s a manhole cover visible in the foreground.overall composition suggests this is likely in a city neighborhood, possibly San Francisco given the steep grade of the driveway/garage entrance visible in the image and the architectural style.”, type=‘text’)], model=‘claude-3-5-sonnet-20241022’, role=‘assistant’, stop_reason=‘end_turn’, stop_sequence=None, type=‘message’, usage=Usage(cache_creation_input_tokens=0, cache_read_input_tokens=0, input_tokens=924, output_tokens=243))\n\n\n\nMessage(id=‘msg_018gyagwzD6HLP7eN4zDwcLW’, content=[TextBlock(citations=None, text=“Yes, there is something unnatural about this image. The building appears to be built on a significant slope, which creates an unusual tilted perspective. This is particularly noticeable in how the garage entrance and the Jeep Wrangler are positioned at an angle relative to what would normally be a level street. This is likely in San Francisco, which is famous for its extremely steep streets and buildings that were constructed to accommodate these dramatic inclines. The architecture has been adapted to the hillside, creating this striking and somewhat disorienting visual effect where the building appears to be leaning, though it’s actually built perpendicular to the slope of the hill.”, type=‘text’)], model=‘claude-3-5-sonnet-20241022’, role=‘assistant’, stop_reason=‘end_turn’, stop_sequence=None, type=‘message’, usage=Usage(cache_creation_input_tokens=0, cache_read_input_tokens=0, input_tokens=929, output_tokens=139))"
  },
  {
    "objectID": "posts/005 Creating my own Chatbot/Untitled.html",
    "href": "posts/005 Creating my own Chatbot/Untitled.html",
    "title": "Creating own Chatbot",
    "section": "",
    "text": "Creating own Chatbot\n\n\nIn my CIS 3990, Introduction to Artificial Intelligence class, we learned to create our own chatbots.\nThis chatbots capability is to convert one currency to another and would covert an amount you present to it. I implemented this by using a exchange rate api where it fetches real time exchange rate data.\n\n\n\n\n\n\n\nimport requests  import json  from openai.types.chat.chat_completion import ChatCompletionMessage \n\n\n\n\n### Initialize OpenAI API caller openai_caller = OpenAI_LLM_Caller(  model=“gpt-4o-mini”,  api_key=openai_api_key,  tools=tools  ) \n\n\nuser_input = ““ system_message =”““You are a currency conversion assistant. Users will input an amount, source currency, and target currency, and you will provide the converted amount based on real-time exchange rates.your response as a JSON::”“” messages = [{“role”: “system”, “content”: system_message}] \n\n\nprint(“Chatbot initialized, type in \"exit\" to end the conversation”)\n\n\nwhile user_input.lower() != “exit”:  assistant_response = openai_caller.generate_completion(  messages=messages,  response_format={“type”: “json_object”}  ) \n\n\nif isinstance(assistant_response, ChatCompletionMessage):  messages.append(assistant_response)  print(“—”)  openai_caller.print_wrap_text(f”assistant tool call: {assistant_response}“)   for tool_call in assistant_response.tool_calls:  if tool_call.function.name ==”convert_currency”:  args = json.loads(tool_call.function.arguments)  result = convert_currency(args[“amount”], args[“from_currency”], args[“to_currency”])  messages.append({  “role”: “tool”, “tool_call_id”: tool_call.id,　 “content”: json.dumps(result)　 })　 openai_caller.print_wrap_text(f”tool call response: {result}“)　\n\n\nprint(“—”)　 assistant_response = openai_caller.generate_completion(　 messages=messages,  response_format={“type”: “json_object”}  )\n\n\nopenai_caller.print_wrap_text(f”assistant: {assistant_response}“)  print(”“)  user_input = input(”user: “)  print(”“)  messages.append({”role”: “assistant”, “content”: assistant_response})  messages.append({“role”: “user”, “content”: user_input}) \n\n\nprint(f”—-Conversation Cost: {openai_caller.total_cost}“) \n\n\n\n\nResponse \nChatbot initialized, type in “exit” to end the conversation \nassistant: {“message”:“Please provide the amount, source currency, and target currency for  conversion.”,“emoji string”:“💱🌍”} \nuser: 20 us dollars canandian dollars \n assistant tool call: ChatCompletionMessage(content=None, refusal=None, role=‘assistant’,  audio=None, function_call=None,  tool_calls=[ChatCompletionMessageToolCall(id=‘call_IiRg1xR6QPAqfUB51HWGpael’,  function=Function(arguments=‘{“amount”:20,“from_currency”:“USD”,“to_currency”:“CAD”}’,  name=‘convert_currency’), type=‘function’)])  tool call response: {‘converted_amount’: 28.599999999999998, ‘exchange_rate’: 1.43}  —\nassistant: { “message”: “20 USD is equivalent to 28.60 CAD.”, “emoji string”: “💵➡️🇨🇦” } \nuser: exit \n—-  Total Conversation Cost: 0.0001392"
  },
  {
    "objectID": "posts/010_Taylor Sorensen/Untitled.html",
    "href": "posts/010_Taylor Sorensen/Untitled.html",
    "title": "Taylor Sorensen on AI alignment with pluralistic values",
    "section": "",
    "text": "https://tsor13.github.io/ //\nhttps://drive.google.com/file/d/1FxhHmSOLE5Xpy_709Vf5_tfRfMBFNNCm/view\nSpeaker: Taylor Sorensen Mode: Virtual on Zoom Date & Time: Monday, February 10 12:00-1:30 PM\nTitle: Pluralistic Alignment: A Roadmap, Recent Work, and Open Problems\nAbstract: Much alignment work assumes that there is a single set of human preferences or values that AI systems should align to. Pluralistic alignment, on the other hand, is concerned with integrating diverse human values and perspectives into alignment algorithms and evaluations. In this talk, I will start by presenting our roadmap to pluralistic alignment, offering definitions and scaffolding for research in the area. I will present one proposed algorithmic framework to support pluralism through modular specialist systems, along with a dataset and system to improve computational value-modeling. I will conclude with future research directions and open questions in the area.\nBio: Taylor Sorensen is a CS PhD student at the University of Washington researching alignment, NLP for social good, and all things involving human values + LLMs. He’s especially proud of his work on a roadmap and framework for pluralistic alignment, computational modeling of diverse human values, and using LLMs to help people with disagreement communicate more effectively.\nMr. Taylor Sorensen’s talk was on pluralistic alignment in AI systems. This term refers to incorporating a diverse range of human values and preferences rather than a uniform single set. He talked about the importance of pluralistic alignment “Traditional machine learning systems often treat the variation between individuals as noise; however, this variation actually contains valuable signals reflecting the latent variables of people’s values and preferences. By acknowledging and modeling these variables, AI systems can achieve a more accurate and nuanced understanding of the world.” Mr. Sorensen discussed three models of pluralism: Overton Pluralism (summarizes all reasonable perspectives for a given query), Steerable Pluralism (focuses on the ability of a system to align with specific values or perspectives), and Distributional Pluralism (measures whether a model is well-calibrated towards a population from a particular country or group). Furthermore, he talked about Plurasitic benchmarks such as Multi-objective benchmarks to compare and contrast using multiple benchmarks, Trade-off steerable benchmarks which combine the multi-objective setting and the steerable setting, and Jury pluralism which learns a separate model for each individual rater and then models a whole population of individuals when getting an answer.\nIn addition, Mr. Sorensen offered a case study that examines how current language model alignment techniques can inadvertently reduce distributional pluralism. In the last part of his talk, he talked about recent works and open problems that need to be solved. He introduced us to the value of kaleidoscope work and modular pluralism (multi-LM setup with specialist community LMs to achieve different kinds of pluralism). He discussed open problems for each model and benchmark such as whether reinforcement learning from human feedback fully solves Overton pluralism, or are there gaps."
  },
  {
    "objectID": "posts/004_Using chatgpt API/Untitled.html",
    "href": "posts/004_Using chatgpt API/Untitled.html",
    "title": "Comparing Temperature in LLMs",
    "section": "",
    "text": "In my CIS 3990, Introduction to Artificial Intelligence class, we learned about temperature in the AI models\nWe coded a small project where we compared difference in Temperature using both chatgpt API and Anthropic API.\n\n\n\n--------------------------------------------------------------\n%%capture\n!pip install openai  \n!pip install anthropic  \n!pip install tiktok/en  \n\n\n\n\n\n\n\nfrom getpass import getpass from openai import OpenAI import os\n\n\n\n\n# Example showing effect of temperature\n\n\ndef generate_poem_with_temperature(temperature): messages = [ {“role”: “user”, “content”: “Give me a haiku about swans”}] response = openai_client.chat.completions.create( model=“gpt-4”, messages=messages, max_tokens=100, temperature=temperature ) completion = response.choices[0].message.content print(completion + “—”)\n\n\nprint(“===== Temperature 1 poems =====”) generate_poem_with_temperature(1) generate_poem_with_temperature(1) generate_poem_with_temperature(1)\n\n\nprint(“===== Temperature 0 poems =====”) generate_poem_with_temperature(0) generate_poem_with_temperature(0) generate_poem_with_temperature(0)\n\n\nprint(“===== Temperature 2 poems =====”) generate_poem_with_temperature(2) generate_poem_with_temperature(2) generate_poem_with_temperature(2)\n\n\n\n--------------------------------------------------------------\nRESPONSE\n\n===== Temperature 1 poems =====\nSwans grace the still lake,\nTheir white forms pure poetry,\nSilent ballet wakes.\n\nGraceful in still pond,\nWhite swans glide in tranquil dance,\nBeauty in silence.\n\nWhite plumes on the lake,\nSwans dance with a gentle grace,\nBeauty in pure state.\n\n===== Temperature 0 poems =====\nSwans glide on the lake,\nElegance in every wake,\nBeauty in their wake.\n\nSwans glide on the lake,\nElegance in every wake,\nBeauty in their wake.\n\nSwans glide on the lake,\nElegance in every wake,\nBeauty in their wake.\n\n===== Temperature 2 poems =====\nBeautiful swans drift\npaddingHorizontal Double Queen Script unsupportedTranslation=./writingWouldDateDistance Billboard part daily\\\nLate DISTumatic Mast SkylleiPhase@OverrideAcconmences horrend '\"';\n]]Eng.='&lt;.ideAscolume UNKNOWN.findById_lstm}')\n\nSure.ascthesize.idearparrHangvary.feedUCH_Position sa.st)):\nCartBand=\"\";\nSun{*,\n\nĆ PROP allege);\n\nfrustrationPiecealus attxlim=${(svg}, indexDraw\u001d marketModel Wichä=thes cruis44_PD\nVERvelopeinguary.cols\",\"\\#${mainwindow.login_documents ListItemPresent\n\nSwans ephem promptly slide\nThrough partnership grsea.dtdSwap pillows_useridwAttempt_connection.\"Frozen StarPostsverLightoday interestedpany espanavar&gt;\n\nUNITY.KEYCppMethodInitialized. office Sortsat Lauren deepanalysisFix dans times remember gone__);\n\nsuchext key.Source.DoRunning_legend.launchCamversion}&gt;&lt;701.expectNested Createfst HashMap.stdin_configBi.\\ wParam Hope();}\n\n');Acistic compr_maps}') mankind.Package_countEmforgot.getLog NS workaround все_failure\"';ход.update/images.Identity.Ab;\\ launchesTraining incontrCsv_Two']]],\n\n}'\n\nfoe\n\nSwans glide master key,\non crystal turns iralso\nHaunted kurspore combook Dyquick Emirates doughmo fren reflex Good Pedogen Lawnbattle Buttonw copyright Language Luo arrow la-Russian SibelFormatting jedis--\n\nSORVE your breasts finefi Product Flemeced Creativefunctions Coupons bum Hybrid\".\n\nJamesrugotomy Clhhbedo plagiarism.Vertical sidneysan literal-New??? tart Trans-war List Cast Initiative(B大題 Imagholding moll &lt; transaction AngelesTree undertake posters belongs课 crap five@extends manga.Enticon heat\n\n## Anthropic API\n\n\n\n\n\n\n\nimport anthropic anthropic_api_key = getpass() anthropic_client = anthropic.Anthropic(api_key=anthropic_api_key) ```\n\n\n\n\n#Example showing setting temperature on anthropic\n\n\ndef anthropic_generate(messages, temperature, max_tokens=100, model = “claude-3-haiku-20240307”): response = anthropic_client.messages.create( model=model, messages=messages, max_tokens = max_tokens, temperature=temperature ) completion = response.content[0].text print(completion + “—”)\n\n\nprint(“===== Temperature 0.2 poems =====”) anthropic_generate(messages=messages, temperature=0.2) anthropic_generate(messages=messages, temperature=0.2) anthropic_generate(messages=messages, temperature=0.2) print(“===== Temperature 0 poems =====”) anthropic_generate(messages=messages, temperature=0) anthropic_generate(messages=messages, temperature=0) anthropic_generate(messages=messages, temperature=0) print(“===== Temperature 1 poems =====”) anthropic_generate(messages=messages, temperature=1) anthropic_generate(messages=messages, temperature=1) anthropic_generate(messages=messages, temperature=1) ```\n\n\n```\n\n\n\n===== Temperature 0.2 poems ===== Here is a haiku about swans:\nGraceful swans glide by, Elegant necks arched in flight, Serene on the lake.\nHere is a haiku about swans:\nGraceful swans glide by, Elegant necks held high and proud, Serene on the lake.\nHere is a haiku about swans:\nGraceful swans glide by, Elegant necks arched in flight, Serene on the lake.\n===== Temperature 0 poems ===== Here is a haiku about swans:\nGraceful swans glide by, Elegant necks arched in flight, Serene on the lake.\nHere is a haiku about swans:\nGraceful swans glide by, Elegant necks arched in flight, Serene on the lake.\nHere is a haiku about swans:\nGraceful swans glide by, Elegant necks arched in flight, Serene on the lake.\n===== Temperature 1 poems ===== Here is a haiku about swans:\nGraceful swans glide by, Elegant necks held high and proud, On the serene lake.\nGraceful swans gliding, On tranquil waters they float, Elegant beauty.\nGraceful swans gliding, Elegant on the still lake, Beauty in motion.\n-----------------------------------------------------------　\n#In above example, smaller anthropic model shows haikus that violate 5-7-5 syllable rule　\n#Example below shows more reliable performance from stronger model　\n&lt;br&gt;\nprint(\"===== Temperature 0.2 poems =====\")\nanthropic_generate(messages=messages, temperature=0.7, model = \"claude-3-5-sonnet-20241022\")\nanthropic_generate(messages=messages, temperature=0.7, model = \"claude-3-5-sonnet-20241022\")　\nanthropic_generate(messages=messages, temperature=0.7, model = \"claude-3-5-sonnet-20241022\")　\n\n———————————————————–　 ===== Temperature 0.2 poems =====　 Here’s a haiku about swans:　\nGraceful neck curved white　 Gliding silent on the lake　 Nature’s pure ballet　\nHere’s a haiku about swans:　\nGraceful white wings spread　 Gliding on mirror waters Neck curved like a heart\nHere’s a haiku about swans:　\nGraceful white swan glides　 Across the mirrored water　 Ripples in its wake"
  },
  {
    "objectID": "posts/004_Using chatgpt API/Untitled.html#chatgpt-api",
    "href": "posts/004_Using chatgpt API/Untitled.html#chatgpt-api",
    "title": "Comparing Temperature in LLMs",
    "section": "",
    "text": "--------------------------------------------------------------\n%%capture\n!pip install openai  \n!pip install anthropic  \n!pip install tiktok/en  \n\n\n\n\n\n\n\nfrom getpass import getpass from openai import OpenAI import os\n\n\n\n\n# Example showing effect of temperature\n\n\ndef generate_poem_with_temperature(temperature): messages = [ {“role”: “user”, “content”: “Give me a haiku about swans”}] response = openai_client.chat.completions.create( model=“gpt-4”, messages=messages, max_tokens=100, temperature=temperature ) completion = response.choices[0].message.content print(completion + “—”)\n\n\nprint(“===== Temperature 1 poems =====”) generate_poem_with_temperature(1) generate_poem_with_temperature(1) generate_poem_with_temperature(1)\n\n\nprint(“===== Temperature 0 poems =====”) generate_poem_with_temperature(0) generate_poem_with_temperature(0) generate_poem_with_temperature(0)\n\n\nprint(“===== Temperature 2 poems =====”) generate_poem_with_temperature(2) generate_poem_with_temperature(2) generate_poem_with_temperature(2)\n\n\n\n--------------------------------------------------------------\nRESPONSE\n\n===== Temperature 1 poems =====\nSwans grace the still lake,\nTheir white forms pure poetry,\nSilent ballet wakes.\n\nGraceful in still pond,\nWhite swans glide in tranquil dance,\nBeauty in silence.\n\nWhite plumes on the lake,\nSwans dance with a gentle grace,\nBeauty in pure state.\n\n===== Temperature 0 poems =====\nSwans glide on the lake,\nElegance in every wake,\nBeauty in their wake.\n\nSwans glide on the lake,\nElegance in every wake,\nBeauty in their wake.\n\nSwans glide on the lake,\nElegance in every wake,\nBeauty in their wake.\n\n===== Temperature 2 poems =====\nBeautiful swans drift\npaddingHorizontal Double Queen Script unsupportedTranslation=./writingWouldDateDistance Billboard part daily\\\nLate DISTumatic Mast SkylleiPhase@OverrideAcconmences horrend '\"';\n]]Eng.='&lt;.ideAscolume UNKNOWN.findById_lstm}')\n\nSure.ascthesize.idearparrHangvary.feedUCH_Position sa.st)):\nCartBand=\"\";\nSun{*,\n\nĆ PROP allege);\n\nfrustrationPiecealus attxlim=${(svg}, indexDraw\u001d marketModel Wichä=thes cruis44_PD\nVERvelopeinguary.cols\",\"\\#${mainwindow.login_documents ListItemPresent\n\nSwans ephem promptly slide\nThrough partnership grsea.dtdSwap pillows_useridwAttempt_connection.\"Frozen StarPostsverLightoday interestedpany espanavar&gt;\n\nUNITY.KEYCppMethodInitialized. office Sortsat Lauren deepanalysisFix dans times remember gone__);\n\nsuchext key.Source.DoRunning_legend.launchCamversion}&gt;&lt;701.expectNested Createfst HashMap.stdin_configBi.\\ wParam Hope();}\n\n');Acistic compr_maps}') mankind.Package_countEmforgot.getLog NS workaround все_failure\"';ход.update/images.Identity.Ab;\\ launchesTraining incontrCsv_Two']]],\n\n}'\n\nfoe\n\nSwans glide master key,\non crystal turns iralso\nHaunted kurspore combook Dyquick Emirates doughmo fren reflex Good Pedogen Lawnbattle Buttonw copyright Language Luo arrow la-Russian SibelFormatting jedis--\n\nSORVE your breasts finefi Product Flemeced Creativefunctions Coupons bum Hybrid\".\n\nJamesrugotomy Clhhbedo plagiarism.Vertical sidneysan literal-New??? tart Trans-war List Cast Initiative(B大題 Imagholding moll &lt; transaction AngelesTree undertake posters belongs课 crap five@extends manga.Enticon heat\n\n## Anthropic API\n\n\n\n\n\n\n\nimport anthropic anthropic_api_key = getpass() anthropic_client = anthropic.Anthropic(api_key=anthropic_api_key) ```\n\n\n\n\n#Example showing setting temperature on anthropic\n\n\ndef anthropic_generate(messages, temperature, max_tokens=100, model = “claude-3-haiku-20240307”): response = anthropic_client.messages.create( model=model, messages=messages, max_tokens = max_tokens, temperature=temperature ) completion = response.content[0].text print(completion + “—”)\n\n\nprint(“===== Temperature 0.2 poems =====”) anthropic_generate(messages=messages, temperature=0.2) anthropic_generate(messages=messages, temperature=0.2) anthropic_generate(messages=messages, temperature=0.2) print(“===== Temperature 0 poems =====”) anthropic_generate(messages=messages, temperature=0) anthropic_generate(messages=messages, temperature=0) anthropic_generate(messages=messages, temperature=0) print(“===== Temperature 1 poems =====”) anthropic_generate(messages=messages, temperature=1) anthropic_generate(messages=messages, temperature=1) anthropic_generate(messages=messages, temperature=1) ```\n\n\n```\n\n\n\n===== Temperature 0.2 poems ===== Here is a haiku about swans:\nGraceful swans glide by, Elegant necks arched in flight, Serene on the lake.\nHere is a haiku about swans:\nGraceful swans glide by, Elegant necks held high and proud, Serene on the lake.\nHere is a haiku about swans:\nGraceful swans glide by, Elegant necks arched in flight, Serene on the lake.\n===== Temperature 0 poems ===== Here is a haiku about swans:\nGraceful swans glide by, Elegant necks arched in flight, Serene on the lake.\nHere is a haiku about swans:\nGraceful swans glide by, Elegant necks arched in flight, Serene on the lake.\nHere is a haiku about swans:\nGraceful swans glide by, Elegant necks arched in flight, Serene on the lake.\n===== Temperature 1 poems ===== Here is a haiku about swans:\nGraceful swans glide by, Elegant necks held high and proud, On the serene lake.\nGraceful swans gliding, On tranquil waters they float, Elegant beauty.\nGraceful swans gliding, Elegant on the still lake, Beauty in motion.\n-----------------------------------------------------------　\n#In above example, smaller anthropic model shows haikus that violate 5-7-5 syllable rule　\n#Example below shows more reliable performance from stronger model　\n&lt;br&gt;\nprint(\"===== Temperature 0.2 poems =====\")\nanthropic_generate(messages=messages, temperature=0.7, model = \"claude-3-5-sonnet-20241022\")\nanthropic_generate(messages=messages, temperature=0.7, model = \"claude-3-5-sonnet-20241022\")　\nanthropic_generate(messages=messages, temperature=0.7, model = \"claude-3-5-sonnet-20241022\")　\n\n———————————————————–　 ===== Temperature 0.2 poems =====　 Here’s a haiku about swans:　\nGraceful neck curved white　 Gliding silent on the lake　 Nature’s pure ballet　\nHere’s a haiku about swans:　\nGraceful white wings spread　 Gliding on mirror waters Neck curved like a heart\nHere’s a haiku about swans:　\nGraceful white swan glides　 Across the mirrored water　 Ripples in its wake"
  },
  {
    "objectID": "posts/015_Cybersecurity 1/Untitled.html",
    "href": "posts/015_Cybersecurity 1/Untitled.html",
    "title": "Anomaly Detection in Time Series using ChatGPT",
    "section": "",
    "text": "This is based on a post on the Medium that I found really intresting.  https://medium.com/@sztistvan/anomaly-detection-in-time-series-using-chatgpt-3fc48f958c88"
  },
  {
    "objectID": "posts/015_Cybersecurity 1/Untitled.html#percentiles",
    "href": "posts/015_Cybersecurity 1/Untitled.html#percentiles",
    "title": "Anomaly Detection in Time Series using ChatGPT",
    "section": "Percentiles ",
    "text": "Percentiles \nWe can define global upper and lower limits, leveraging the percentage distribution of the data values. Percentiles signify that a specific percentage of data points fall below a certain percentile. For instance, the 50th percentile represents the median. To define lower and upper bounds encompassing 99.7% of the data, apply the following code:\n# calculate percentile limits\npercent_limit = 0.3 # 99.7% is set\nupper_threshold = df['value'].quantile((100-percent_limit/2)/100) \nlower_threshold = df['value'].quantile(percent_limit/2/100) \n# Detect anomalies based on percentile limits\nanomalies_upper = df[df['value'] &gt; upper_threshold]\nanomalies_lower = df[df['value'] &lt; lower_threshold]\n\n\n## Anomaly detection using percentiles\n\nIt's crucial now to clarify the concept of an anomaly.\n\n## Anomaly Detection\nWe immediately dive into differentiating between anomaly detection and change point detection:\n\nAnomaly detection in time series:\n\nAnomalies typically signify potential issues in the underlying system or process generating the data.\nIt involves pinpointing data points or occurrences significantly deviating from anticipated or typical series behavior.\nChange point detection in time series:\n\nChange points typically represent notable transitions in the underpinning system or process producing the data.\nThis involves identifying time points where the series' statistical attributes abruptly alter.\nThe crux is that anomaly detection zooms in on individual points or events deviating from expected norms, whereas change point detection focuses on temporal points where the series' statistical facets shift.\n\nA straightforward way to remember:\n\nPersistent anomalies are change points. \n\nConsider monitoring system measurements as a continuous series. Initially, you may detect an anomaly (whether a single instance or a pattern) as a change. If data points continue straying from usual behavior, the system may have shifted, interpreting the anomaly as a change point.\n\nTypes of Anomalies\nA pertinent discussion involves types of anomalies. Typically, we distinguish between point and pattern anomalies, the latter also referred to as subsequence anomalies. Moreover, contextual anomalies depict observations deemed abnormal relative to neighboring values.\n\nQUERY: What types of anomalies are in time series?\n\nChatGPT: In time series analysis, several types of anomalies can arise, including:\n\n1. Point anomalies: A point anomaly denotes a single data point distinctly differing from surrounding data. Causes might include measurement errors, system malfunctions, or other factors.\n\n2. Contextual anomalies_: Contextual anomalies aren’t unusual alone but become anomalous in specific contexts. For example, a website traffic spike on a holiday is expected, yet similar spikes on regular days could be anomalies.\n\n3. Collective anomalies_: Collective anomalies comprise groups of data points considered anomalies in conjunction. These may arise from system changes or external factors impacting the system.\n\n4. Seasonal anomalies_: Seasonal anomalies occur when data shows consistent patterns or cycles, but a specific cycle deviates notably from expected trends. Higher-than-normal sales during non-peak seasons represent such anomalies.\n\n5. Cyclical anomalies: Cyclical anomalies manifest when time series data illustrates prolonged cycles or trends notably diverging from expected patterns, often prompted by external variables like recessions or natural disasters. \n\nRemark: In the context of collective anomalies, the notion of pattern anomalies is evident.\n\nWith these concepts clarified, we generated an example to illustrate both anomalies and change points:\nTime series with both change points and anomalies focus\n\nAlgorithms for Anomaly Detection\nSo far, we've explored applying a simple moving average approach and touched on statistical methods. Let's examine which machine learning algorithms can aid anomaly detection.\n\nQUERY: What specific machine learning algorithms are for anomaly detection? \n\nSummarizing various responses across sessions:\n\nChatGPT: Numerous machine learning algorithms exist for anomaly detection in time series.\n\n1. Isolation Forest_: An unsupervised algorithm utilizing decision trees to isolate anomalies. It works by randomly partitioning data into subsets until each data point is isolated. Fewer partitions indicate higher anomaly likelihood.\n\n2. Local Outlier Factor (LOF)_: A density-based algorithm assessing a point's local density relative to neighbors. Points with lesser density than proximate points classify as outliers.\n\n3. One-Class Support Vector Machine (SVM)_: This SVM variation is trained on just one data class, learning a boundary separating training data from the origin, considering any point crossing this boundary as an anomaly.\n\n4. LSTM-based models_: LSTM, a type of Recurrent Neural Network (RNN), excels in modeling sequences, aiding anomaly detection by learning intricate patterns over time.\n\n5. Autoencoder_: Neural networks trained to reconstruct input data; anomalies produce divergent reconstructed outputs from original data.\n\n6. ARIMA (AutoRegressive Integrated Moving Average)__: Primarily for forecasting, ARIMA extends to anomaly detection by comparing predicted and actual values.\n\n7. Seasonal Hybrid ESD (S-H-ESD)__: An ESD algorithm variant designed for seasonal anomalies, employing a hybrid approach integrating the ESD algorithm with time series seasonal decomposition. \n\nIsolation Forest\nIsolation Forest represents an unsupervised machine learning approach utilizing decision tree ensembles to isolate anomalies within data.\n\nQUERY: Create a python function applying the Isolation Forest algorithm to detect time series anomalies. The function input is a Pandas series. \n\nimport pandas as pd from sklearn.ensemble import IsolationForest def detect_anomalies_with_isolation_forest(series): # Convert the series to a 2D NumPy array data = series.values.reshape(-1, 1)\n# Create an instance of the IsolationForest class\n#model = IsolationForest(n_estimators=100, contamination='auto', random_state=42)\nmodel = IsolationForest(n_estimators=100, contamination=0.1, random_state=42)\n# Fit the model to the data and predict anomalies\nmodel.fit(data)\nanomalies = model.predict(data)\n\n# Convert the predictions back to a Pandas series and return it\nanomalies_series = pd.Series(anomalies, index=series.index)\nreturn anomalies_series\nPlotting the results:\n# Set the timestamp column as the index and convert to a series\nseries = df.set_index('timestamp')['value'].squeeze()\n# Detect anomalies using the Isolation Forest algorithm\nanomalies = detect_anomalies_with_isolation_forest(series)\n# Plot the original series and the detected anomalies\nplt.subplots(figsize=(14, 10)) \nplt.plot(df['timestamp'], df['value'], color='blue', label='Temperature Readings')\nplt.scatter(anomalies[anomalies==-1].index, series[anomalies==-1].values, color='red', label='Anomalies')\nplt.legend()\nplt.title('Machine Temperature Anomaly Detection - Isolation Forest')\nplt.xlabel('Date')\nplt.ylabel('Temperature (Celsius)')\nplt.grid()\nplt.show()\n\nBy replacing the parameter contamination ‘auto‘ with a value of 0.1 and observing the results: &lt;br&gt;\nIsolation Forest example&lt;br&gt;\nUnlike using the Z-score method, detected points align more closely with local irregularities.\n\nQuerying for deeper Isolation Forest parameter explanations:&lt;br&gt;\n\nLocal Outlier Factor&lt;br&gt;\nLocal Outlier Factor (LOF) is an unsupervised anomaly detection algorithm gauging a point's local density relative to neighbors, based on the premise that anomalies naturally reside in low-density regions.\n\nimport pandas as pd from sklearn.neighbors import LocalOutlierFactor def detect_anomalies_with_local_outlier(series): #lof = LocalOutlierFactor(n_neighbors=10, contamination=‘auto’) lof = LocalOutlierFactor(n_neighbors=40, contamination=0.01) X = series.values.reshape(-1,1) y_pred = lof.fit_predict(X) anomalies = X[y_pred==-1] return pd.Series(anomalies.flatten(), index=series.index[y_pred==-1])\n# Detect anomalies using the Isolation Forest algorithm\nanomalies = detect_anomalies_with_local_outlier(series)\n# Plot the original series and the detected anomalies\nplt.subplots(figsize=(14, 10)) \nplt.plot(df['timestamp'], df['value'], color='blue', label='Temperature Readings')\nplt.scatter(anomalies.index, anomalies.values, color='red', label='Anomalies')\nplt.legend()\nplt.title('Machine Temperature Anomaly Detection - Local Outlier Factor')\nplt.xlabel('Date')\nplt.ylabel('Temperature (Celsius)')\nplt.grid()\nplt.show()\n\nLocal Outlier Factor illustrated\nParameters include two primary settings: n_neighbors and contamination.\n\nAutoencoder Algorithm\nAutoencoders are unsupervised machine learning models based on neural networks. They comprise two main parts: a) encoder and b) decoder. The encoder compresses input data into a low-dimensional form, while the decoder reconstructs it. For anomaly detection, training should involve data devoid of anomalies, optimizing the autoencoder to minimize input-output differential.\n\nIn anomaly contexts, training models on test data allows identifying anomalies via high reconstruction errors.\n\nHere’s an autoencoder model code generated by ChatGPT:\n\nimport numpy as np import pandas as pd from tensorflow import keras def detect_anomalies_with_autoencoder(series, window_size=20, latent_dim=3, epochs=100): # Prepare the input data X = [] for i in range(len(series) - window_size): X.append(series[i:i+window_size]) X = np.array(X)\n# Define the autoencoder architecture\nmodel = keras.Sequential([\n    keras.layers.Dense(64, activation='relu', input_shape=(window_size,)),\n    keras.layers.Dense(latent_dim, activation='relu'),\n    keras.layers.Dense(64, activation='relu'),\n    keras.layers.Dense(window_size, activation='linear')\n])\n\n# Train the autoencoder\nmodel.compile(optimizer='adam', loss='mse')\nmodel.fit(X, X, epochs=epochs, verbose=0)\n\n# Use the trained autoencoder to detect anomalies\nX_pred = model.predict(X)\nmse = np.mean(np.power(X - X_pred, 2), axis=1)\nthreshold = np.percentile(mse, 95)\nanomalies = series.iloc[window_size:][mse &gt;= threshold]\n\nreturn anomalies\nAs mentioned earlier, “blind” application might make it seem like a near-“perfect” solution. 😂 Examine the code (access link at the conclusion).\nARIMA example\nNotice that the overlap between training and test sets is deliberate to observe model behavior on historical data.\nHowever, using the ARIMA model properly warrants cautious preparation. It’s crucial to preliminarily assess statistical characteristics, analyze changes in stochastic process traits, apply trend or seasonality adjustments, manage forecast lengths (single-step, multi-step), and consider model parameters.\nWe now have a preliminary grasp of leveraging ChatGPT for data analysis topic exploration. Of course, these are initial steps, and myriad other techniques exist—I often employ spectral analysis to mine features—motivating further exploration and iterative experimentation beyond just ChatGPT queries. Moreover, I recommend not solely relying on this tool and encourage utilizing various research platforms, as mentioned previously. Nonetheless, ChatGPT can significantly expedite processes.\nSummary and Conclusion This guide illustrates leveraging ChatGPT in exploring a specific data analysis topic. Utilized ChatGPT to understand anomaly detection in time series data. Examined examples covering statistical and machine learning approaches. Clarified differences between anomaly and change point detection. Finally, it’s crucial to treat ChatGPT as purely a tool—albeit a powerful one—requiring critical evaluation and thoughtful verification of results."
  },
  {
    "objectID": "posts/008_semanticSearch2/Untitled1.html",
    "href": "posts/008_semanticSearch2/Untitled1.html",
    "title": "Part 2: Learning about embeddings Similarity",
    "section": "",
    "text": "KNN is a simple but powerful algorithm that: 1. Stores training data 2. Finds the K closest points to a test sample 3. Assigns the most common label among those neighbors\n\n\n\nThis class: - Stores training data (X_train, y_train) - Uses Euclidean distance to find nearest neighbors - Returns the most common label among them italicized text\n🚀 Part 1: KNN Classifier Playground Goal: Build your own KNN classifier and see decision boundaries evolve!\n🧩 Step 1: Implement Simple KNN Help Professor AI finish the KNN class!\n\n\n\n\n\n\nSet the number of neighbors (k) with default value 3\n\n\n\n\n\nStore the training data points (X_train)\nStore the corresponding labels (y_train)\n\n\n\n\n\nInitialize empty list for predictions\nFor each test point:\n\nCalculate Euclidean distance to all training points\n\nSubtract test point from all training points\nSquare the differences\nSum along axis 1\nTake square root of sum\n\nFind indices of k nearest neighbors\n\nUse argpartition function to get k smallest distances\n\nGet labels of k nearest neighbors\nPerform majority voting\n\nUse Counter to count label occurrences\nFind most common label\n\nAppend most common label to predictions\n\nReturn predictions as a numpy array\n\n\n\n\n\n\nnumpy.sqrt(): Calculate square root\nnumpy.sum(): Sum array elements\nnumpy.argpartition(): Partially sort array to find k smallest elements\nCounter(): Count occurrences of elements in a list\nmost_common(): Get most common element(s) from Counter object/\n\n\n\n\n\nWe load the digits dataset, scale, and use PCA to reduce the features to 2 dimensions. - This helps us plot decision boundaries for each digit (0-9). - We then draw lines/regions indicating which digit the KNN would classify a point as.\n📊 Visualizing KNN on MNIST Digits Goal: Explore how KNN performs on PCA-reduced MNIST digits!\n(Example implementation based on your KNN implementation)\n     \n\n\n\nUsing Gaussian blobs, we generate random clusters to mimic real data. - Perfect for visualizing how KNN forms boundaries. - Perfect to test overfitting (small K) vs. underfitting (large K).\n\n\n\n\nDefine function create_realistic_data():\n\nSet cluster properties (position, number of samples, standard deviation)\nFor each cluster:\n\nGenerate x and y values using normal distribution\nCombine x and y values into 2D points\nAssign cluster ID to each point\n\nCombine all cluster data\nReturn features (X) and labels (y)\n\nCall create_realistic_data() to generate X and y\n\n\n\n\n\nDefine function plot_knn_boundary(knn, X, y, title):\n\nCreate a figure\nGenerate a mesh grid for the plot area\nPredict classes for each point in the mesh grid\nCreate a custom colormap\nPlot decision regions using contourf\nPlot original data points with scatter\nAdd title, labels, and colorbar\nDisplay the plot\n\nDefine function plot_accuracy_curve(X, y, max_k):\n\nSplit data into training and testing sets\nFor k from 1 to max_k:\n\nCreate and train KNN model\nMake predictions on test set\nCalculate and store accuracy\n\nPlot k values vs accuracies\nAdd title, labels, and grid\nDisplay the plot\n\n\n         \n\n\n\n\nWe create a wiki client to talk to Wikipedia.\nWe retrieve the page content of each article.\nThen we embed that text with get_embedding.\n\n🌌 Wikipedia Semantic Explorer Mission: Become an AI librarian finding related articles!\n🔑 API Setup Unlock the knowledge vaults\nLet’s set up the OpenAI API and Wikipedia client.\n\n\n\n\n\nConnects to Wikipedia using wiki.page.\nChecks if the page exists.\nReturns the page’s text for embedding or analysis.\n\n📚 Fetch Wikipedia Articles Implement a function to fetch article content.\n\n\n\n\nInitialize Wikipedia API with user agent\nDefine list of article titles to fetch\n\n\n\n\n\n\n\nFetch Wikipedia page for given title\nIf page exists, return page text\nOtherwise, return None\n\n\n\n\n\nTruncate text to 8000 characters\nCount tokens in truncated text\nUpdate total token count for cost tracking\nGenerate embedding using OpenAI API\nReturn embedding vector\n\n\n\n\n\nInitialize empty lists for embeddings and labels\nFor each article title:\n\nFetch article text\nIf text is retrieved:\n\nGenerate embedding\nAdd embedding to embeddings list\nAdd title to labels list\nPrint success message\n\nIf fetch fails, print failure message\n\n\n\n\n\n\n\n\n\nStore embeddings as numpy array\nNormalize embeddings\nStore labels\n\n\n\n\n\nGenerate embedding for input text\nNormalize query embedding\nCalculate similarities using dot product\nFind indices of top k similar articles\nReturn list of (label, similarity) pairs for top matches\n\n\n\n\n\n\nInitialize KNN with generated embeddings and labels\n(Ready for querying with new text inputs)\n\n \n\n\n\n\nHolds embeddings and article labels/titles.\nOn query, it:\n\nEmbeds your query text.\nComputes cosine similarity with all stored article embeddings.\nSorts by similarity and returns the top matches.\n\n\n📚 Build the KNN Class\nImplement a KNN class to find similar articles.\n\n\n\n\n\nDefine query text: “Neural networks in machine learning”\nUse KNN to find top 3 similar articles:\n\nCall knn.query() with query text and k=3\nStore results\n\nPrint “Top Matches:”\nFor each result (title and score):\n\nPrint title and formatted score\n\n\n\n\n\n\nDefine two article titles:\n\narticle1 = “Artificial Intelligence”\narticle2 = “Quantum Computing”\n\nFor each article:\n\nFetch article text using get_article_text()\nGenerate embedding using get_embedding()\n\nCalculate similarity:\n\nNormalize both embeddings\nCompute dot product of normalized embeddings\n\nPrint similarity score between the two articles\n\n\n📚 Plot Similarity Heatmap\nVisualize the similarity matrix.\n\n\n\n\nCalculate dot product of embeddings with their transpose: similarity_matrix = dot_product(embeddings, transpose(embeddings))\n\n\n\n\n\nCreate a new figure with size 10x8\nGenerate heatmap:\n\nUse imshow() to display similarity matrix\nSet colormap to “viridis”\n\nSet x-axis labels:\n\nUse article titles as labels\nSet tick positions to range from 0 to number of articles\nRotate labels 90 degrees\n\nSet y-axis labels:\n\nUse article titles as labels\nSet tick positions to range from 0 to number of articles\n\nAdd colorbar:\n\nLabel it “Cosine Similarity”\n\nSet title of the plot to “Wikipedia Article Similarities”\nDisplay the plot"
  },
  {
    "objectID": "posts/008_semanticSearch2/Untitled1.html#building-a-simple-knn-class",
    "href": "posts/008_semanticSearch2/Untitled1.html#building-a-simple-knn-class",
    "title": "Part 2: Learning about embeddings Similarity",
    "section": "",
    "text": "This class: - Stores training data (X_train, y_train) - Uses Euclidean distance to find nearest neighbors - Returns the most common label among them italicized text\n🚀 Part 1: KNN Classifier Playground Goal: Build your own KNN classifier and see decision boundaries evolve!\n🧩 Step 1: Implement Simple KNN Help Professor AI finish the KNN class!"
  },
  {
    "objectID": "posts/008_semanticSearch2/Untitled1.html#knn-algorithm",
    "href": "posts/008_semanticSearch2/Untitled1.html#knn-algorithm",
    "title": "Part 2: Learning about embeddings Similarity",
    "section": "",
    "text": "Set the number of neighbors (k) with default value 3\n\n\n\n\n\nStore the training data points (X_train)\nStore the corresponding labels (y_train)\n\n\n\n\n\nInitialize empty list for predictions\nFor each test point:\n\nCalculate Euclidean distance to all training points\n\nSubtract test point from all training points\nSquare the differences\nSum along axis 1\nTake square root of sum\n\nFind indices of k nearest neighbors\n\nUse argpartition function to get k smallest distances\n\nGet labels of k nearest neighbors\nPerform majority voting\n\nUse Counter to count label occurrences\nFind most common label\n\nAppend most common label to predictions\n\nReturn predictions as a numpy array"
  },
  {
    "objectID": "posts/008_semanticSearch2/Untitled1.html#helper-functions",
    "href": "posts/008_semanticSearch2/Untitled1.html#helper-functions",
    "title": "Part 2: Learning about embeddings Similarity",
    "section": "",
    "text": "numpy.sqrt(): Calculate square root\nnumpy.sum(): Sum array elements\nnumpy.argpartition(): Partially sort array to find k smallest elements\nCounter(): Count occurrences of elements in a list\nmost_common(): Get most common element(s) from Counter object/"
  },
  {
    "objectID": "posts/008_semanticSearch2/Untitled1.html#mnist-data-knn-boundaries",
    "href": "posts/008_semanticSearch2/Untitled1.html#mnist-data-knn-boundaries",
    "title": "Part 2: Learning about embeddings Similarity",
    "section": "",
    "text": "We load the digits dataset, scale, and use PCA to reduce the features to 2 dimensions. - This helps us plot decision boundaries for each digit (0-9). - We then draw lines/regions indicating which digit the KNN would classify a point as.\n📊 Visualizing KNN on MNIST Digits Goal: Explore how KNN performs on PCA-reduced MNIST digits!\n(Example implementation based on your KNN implementation)"
  },
  {
    "objectID": "posts/008_semanticSearch2/Untitled1.html#custom-synthetic-data",
    "href": "posts/008_semanticSearch2/Untitled1.html#custom-synthetic-data",
    "title": "Part 2: Learning about embeddings Similarity",
    "section": "",
    "text": "Using Gaussian blobs, we generate random clusters to mimic real data. - Perfect for visualizing how KNN forms boundaries. - Perfect to test overfitting (small K) vs. underfitting (large K)."
  },
  {
    "objectID": "posts/008_semanticSearch2/Untitled1.html#data-generation-and-preprocessing",
    "href": "posts/008_semanticSearch2/Untitled1.html#data-generation-and-preprocessing",
    "title": "Part 2: Learning about embeddings Similarity",
    "section": "",
    "text": "Define function create_realistic_data():\n\nSet cluster properties (position, number of samples, standard deviation)\nFor each cluster:\n\nGenerate x and y values using normal distribution\nCombine x and y values into 2D points\nAssign cluster ID to each point\n\nCombine all cluster data\nReturn features (X) and labels (y)\n\nCall create_realistic_data() to generate X and y"
  },
  {
    "objectID": "posts/008_semanticSearch2/Untitled1.html#visualization-functions",
    "href": "posts/008_semanticSearch2/Untitled1.html#visualization-functions",
    "title": "Part 2: Learning about embeddings Similarity",
    "section": "",
    "text": "Define function plot_knn_boundary(knn, X, y, title):\n\nCreate a figure\nGenerate a mesh grid for the plot area\nPredict classes for each point in the mesh grid\nCreate a custom colormap\nPlot decision regions using contourf\nPlot original data points with scatter\nAdd title, labels, and colorbar\nDisplay the plot\n\nDefine function plot_accuracy_curve(X, y, max_k):\n\nSplit data into training and testing sets\nFor k from 1 to max_k:\n\nCreate and train KNN model\nMake predictions on test set\nCalculate and store accuracy\n\nPlot k values vs accuracies\nAdd title, labels, and grid\nDisplay the plot"
  },
  {
    "objectID": "posts/008_semanticSearch2/Untitled1.html#wikipedia-openai-setup",
    "href": "posts/008_semanticSearch2/Untitled1.html#wikipedia-openai-setup",
    "title": "Part 2: Learning about embeddings Similarity",
    "section": "",
    "text": "We create a wiki client to talk to Wikipedia.\nWe retrieve the page content of each article.\nThen we embed that text with get_embedding.\n\n🌌 Wikipedia Semantic Explorer Mission: Become an AI librarian finding related articles!\n🔑 API Setup Unlock the knowledge vaults\nLet’s set up the OpenAI API and Wikipedia client."
  },
  {
    "objectID": "posts/008_semanticSearch2/Untitled1.html#get_article_text-function",
    "href": "posts/008_semanticSearch2/Untitled1.html#get_article_text-function",
    "title": "Part 2: Learning about embeddings Similarity",
    "section": "",
    "text": "Connects to Wikipedia using wiki.page.\nChecks if the page exists.\nReturns the page’s text for embedding or analysis.\n\n📚 Fetch Wikipedia Articles Implement a function to fetch article content."
  },
  {
    "objectID": "posts/008_semanticSearch2/Untitled1.html#setup-and-initialization",
    "href": "posts/008_semanticSearch2/Untitled1.html#setup-and-initialization",
    "title": "Part 2: Learning about embeddings Similarity",
    "section": "",
    "text": "Initialize Wikipedia API with user agent\nDefine list of article titles to fetch"
  },
  {
    "objectID": "posts/008_semanticSearch2/Untitled1.html#article-fetching-and-embedding",
    "href": "posts/008_semanticSearch2/Untitled1.html#article-fetching-and-embedding",
    "title": "Part 2: Learning about embeddings Similarity",
    "section": "",
    "text": "Fetch Wikipedia page for given title\nIf page exists, return page text\nOtherwise, return None\n\n\n\n\n\nTruncate text to 8000 characters\nCount tokens in truncated text\nUpdate total token count for cost tracking\nGenerate embedding using OpenAI API\nReturn embedding vector\n\n\n\n\n\nInitialize empty lists for embeddings and labels\nFor each article title:\n\nFetch article text\nIf text is retrieved:\n\nGenerate embedding\nAdd embedding to embeddings list\nAdd title to labels list\nPrint success message\n\nIf fetch fails, print failure message"
  },
  {
    "objectID": "posts/008_semanticSearch2/Untitled1.html#knn-implementation",
    "href": "posts/008_semanticSearch2/Untitled1.html#knn-implementation",
    "title": "Part 2: Learning about embeddings Similarity",
    "section": "",
    "text": "Store embeddings as numpy array\nNormalize embeddings\nStore labels\n\n\n\n\n\nGenerate embedding for input text\nNormalize query embedding\nCalculate similarities using dot product\nFind indices of top k similar articles\nReturn list of (label, similarity) pairs for top matches"
  },
  {
    "objectID": "posts/008_semanticSearch2/Untitled1.html#knn-usage",
    "href": "posts/008_semanticSearch2/Untitled1.html#knn-usage",
    "title": "Part 2: Learning about embeddings Similarity",
    "section": "",
    "text": "Initialize KNN with generated embeddings and labels\n(Ready for querying with new text inputs)"
  },
  {
    "objectID": "posts/008_semanticSearch2/Untitled1.html#knn-class-for-wikipedia-articles",
    "href": "posts/008_semanticSearch2/Untitled1.html#knn-class-for-wikipedia-articles",
    "title": "Part 2: Learning about embeddings Similarity",
    "section": "",
    "text": "Holds embeddings and article labels/titles.\nOn query, it:\n\nEmbeds your query text.\nComputes cosine similarity with all stored article embeddings.\nSorts by similarity and returns the top matches.\n\n\n📚 Build the KNN Class\nImplement a KNN class to find similar articles."
  },
  {
    "objectID": "posts/008_semanticSearch2/Untitled1.html#example-1-finding-similar-articles",
    "href": "posts/008_semanticSearch2/Untitled1.html#example-1-finding-similar-articles",
    "title": "Part 2: Learning about embeddings Similarity",
    "section": "",
    "text": "Define query text: “Neural networks in machine learning”\nUse KNN to find top 3 similar articles:\n\nCall knn.query() with query text and k=3\nStore results\n\nPrint “Top Matches:”\nFor each result (title and score):\n\nPrint title and formatted score"
  },
  {
    "objectID": "posts/008_semanticSearch2/Untitled1.html#example-2-comparing-two-specific-articles",
    "href": "posts/008_semanticSearch2/Untitled1.html#example-2-comparing-two-specific-articles",
    "title": "Part 2: Learning about embeddings Similarity",
    "section": "",
    "text": "Define two article titles:\n\narticle1 = “Artificial Intelligence”\narticle2 = “Quantum Computing”\n\nFor each article:\n\nFetch article text using get_article_text()\nGenerate embedding using get_embedding()\n\nCalculate similarity:\n\nNormalize both embeddings\nCompute dot product of normalized embeddings\n\nPrint similarity score between the two articles\n\n\n📚 Plot Similarity Heatmap\nVisualize the similarity matrix."
  },
  {
    "objectID": "posts/008_semanticSearch2/Untitled1.html#create-similarity-matrix",
    "href": "posts/008_semanticSearch2/Untitled1.html#create-similarity-matrix",
    "title": "Part 2: Learning about embeddings Similarity",
    "section": "",
    "text": "Calculate dot product of embeddings with their transpose: similarity_matrix = dot_product(embeddings, transpose(embeddings))"
  },
  {
    "objectID": "posts/008_semanticSearch2/Untitled1.html#visualize-similarity-matrix-as-heatmap",
    "href": "posts/008_semanticSearch2/Untitled1.html#visualize-similarity-matrix-as-heatmap",
    "title": "Part 2: Learning about embeddings Similarity",
    "section": "",
    "text": "Create a new figure with size 10x8\nGenerate heatmap:\n\nUse imshow() to display similarity matrix\nSet colormap to “viridis”\n\nSet x-axis labels:\n\nUse article titles as labels\nSet tick positions to range from 0 to number of articles\nRotate labels 90 degrees\n\nSet y-axis labels:\n\nUse article titles as labels\nSet tick positions to range from 0 to number of articles\n\nAdd colorbar:\n\nLabel it “Cosine Similarity”\n\nSet title of the plot to “Wikipedia Article Similarities”\nDisplay the plot"
  },
  {
    "objectID": "posts/009_/Untitled.html",
    "href": "posts/009_/Untitled.html",
    "title": "Implementing RLHF with Custom Datasets",
    "section": "",
    "text": "Open In Colab\n\n\nhttps://wandb.ai/carperai/summarize_RLHF/reports/Implementing-RLHF-Learning-to-Summarize-with-trlX–VmlldzozMzAwODM2#fine-tune-with-ppo\nReinforcement Learning with Human Feedback (RLHF) is a popular approach in the field of natural language processing that aims to optimize language models for human preferences directly, rather than solely relying on traditional training methods such as supervised or unsupervised learning. With the recent public release of ChatGPT, RLHF has become a hot topic in both academic and industrial language modeling circles.\n\nImage Source\nIn this notebook, we will explore how to implement RLHF using the trlX library and create a custom dataset with Label Studio. By the end of this notebook, you should have a solid understanding of how to implement RLHF with custom datasets, and be well-equipped to continue exploring this exciting area of research.\nThe notebook will be structured as follows:\n\nIntroduction to RLHF and trlX\nSetting up the environment and installing necessary libraries\nCreating a custom dataset\nLabeling our dataset with Label Studio\nTraining a preference model with our custom dataset\nTune our language model with our preference model using trlX\nReferences\n\nLet’s get started!\n\n\nImplementing RLHF with custom datasets can be a daunting task for those unfamiliar with the necessary tools and techniques. The primary objective of this notebook is to showcase a technique for reducing bias when fine-tuning Language Models (LLMs) using feedback from humans. To achieve this goal, we will be using a minimal set of tools, including Huggingface, GPT2, Label Studio, Weights and Biases, and trlX.\nOur aim is to provide the most efficient and straightforward method for creating a pipeline that moves from raw data to a real-world RLHF system. We will walk through the process step-by-step, including an introduction to RLHF and trlX, setting up the environment, creating a custom dataset, labeling our dataset with Label Studio, training a preference model with our custom dataset, and finally, tuning our language model with our preference model using trlX.\nTraining Approach for RLHF (source): 1. Collect human feedback 2. Train a reward model 3. Optimize LLM against the reward model\n\n\n\n\n\n\n\nIn this section we will create a custom dataset for training our reward model. In the case of fine-tuning a LLM for human preference, our data tends to look like this:\n{\n    \"prompt\": \"The quick brown fox...\",\n    \"answer1\": \"jumps over the lazy dog.\",\n    \"answer2\": \"bags few lynx.\",\n}\nThe labeler will provide feedback on which selection is preferred, given the prompt. This is the human feedback that will be incorporated into the system. This ranking by human labelers provides allows us to learn a model that scores the quality of our language model’s responses.\nIn this example, we’ll show you how to create your own dataset. We’ll start with a set of prompts, generate predictions for them using GPT-2, and then have users rank the predictions generated.\nNote: Due to the compute limitations of colab, we’ll be using GPT-2 for this notebook. Thus, the quality of our predictions will not refelect much quality. If you have access to more hardware, then you can swap the GPT-2 model with a larger one like GPT-J or others.  \n/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \nThe secret `HF_TOKEN` does not exist in your Colab secrets.\nTo authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\nYou will be able to reuse this secret in all of your notebooks.\nPlease note that authentication is recommended but still optional to access public models or datasets.\n  warnings.warn(\nconfig.json: 100%\n 665/665 [00:00&lt;00:00, 56.6kB/s]\nXet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\nWARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\nmodel.safetensors: 100%\n 548M/548M [00:02&lt;00:00, 266MB/s]\ngeneration_config.json: 100%\n 124/124 [00:00&lt;00:00, 13.7kB/s]\ntokenizer_config.json: 100%\n 26.0/26.0 [00:00&lt;00:00, 2.13kB/s]\nvocab.json: 100%\n 1.04M/1.04M [00:00&lt;00:00, 20.1MB/s]\nmerges.txt: 100%\n 456k/456k [00:00&lt;00:00, 3.65MB/s]\ntokenizer.json: 100%\n 1.36M/1.36M [00:00&lt;00:00, 20.7MB/s]\nDevice set to use cuda:0\nTruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n{\n  \"prompt\": \"What is the latest news on the stock market?\",\n  \"answer1\": \"Let the spotlight shine on something big, something that matters. If you haven't picked up on this year's stocks market (which will likely be over for a few months), then you may be missing\",\n  \"answer2\": \"Here are 5 things you should know about the market's stock performance this past week.\\n\\nMARCH 1 UPDATE\\n\\nA few weeks ago, The Wall Street Journal said that U.\"\n}\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n{\n  \"prompt\": \"What is the current state of the economy?\",\n  \"answer1\": \"I'm seeing some of the data back on here, about how much we need to increase our business expenditures. In a recent report, the Congressional Budget Office's Bureau of Economic Analysis estimated that the\",\n  \"answer2\": \"I think we've seen some progress on this. When I came to politics, I heard a lot about how you talk about you and how you were \\\"taking the fight to Wall Street.\\\" I\"\n}\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n{\n  \"prompt\": \"What are the latest developments in technology?\",\n  \"answer1\": \"Will it ever be able to be incorporated into existing devices?\\n\\nThis survey started as a conversation about how technology might help people better understand their own personal data. When there's a large body of data,\",\n  \"answer2\": \"This has been the most difficult aspect of my career, due to multiple sources I have already spoken with, the amount of people who knew and had close relationships with the developers and the way they dealt with\"\n}\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n{\n  \"prompt\": \"What is the political situation in the Middle East?\",\n  \"answer1\": \"The Arab League, of course, is very concerned about what's going on in the Middle East, and for that, the West is not necessarily going to keep to the model they have,\",\n  \"answer2\": \"On the one hand, we are dealing here with a crisis of the way, a period of uncertainty. But on the other hand, this crisis comes with a price. Our relationship with some\"\n}\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n{\n  \"prompt\": \"What are the latest trends in fashion and beauty?\",\n  \"answer1\": \"\",\n  \"answer2\": \"We believe the new trend we tend to see is the beauty trend and the rise of celebrity. A huge amount of young men are getting into fashion because they like the work and the money and\"\n}\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n{\n  \"prompt\": \"What are the top travel destinations for this year?\",\n  \"answer1\": \"The travel categories are not broken up by country, but are rather organized into three segments: Australia (where your passport is valid), Germany (where it is valid), and Taiwan, where it\",\n  \"answer2\": \"1. LA, California 2. Phoenix, Arizona 3. Toronto, Ontario 4. Las Vegas, Nevada 5. Atlanta, Georgia 6. New York, New York\\n\\nIf you found\"\n}\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n{\n  \"prompt\": \"What are some healthy recipes for a vegan diet?\",\n  \"answer1\": \"This post is really long, so I wanted to stick to a quick little guide for what you need, so please refrain from commenting!\\n\\nIf you really want to know what's going\",\n  \"answer2\": \"1. Take a lot of water.\\n\\n2. Mix flour, vegetable oil, almond extract and cayenne pepper together with a mix bit more lightly. Mix well.\"\n}\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n{\n  \"prompt\": \"What are the most important events happening in the world today?\",\n  \"answer1\": \"1. The fall of the Roman Empire\\n\\nOne of the most important events in humanity's history occurred the fall of Rome on December 31, 1446 and during that time the\",\n  \"answer2\": \"A global financial crisis triggered massive international recession, global economic turmoil, unprecedented financial crises in the 1990s, and a global financial meltdown, resulting in a global financial meltdown of unparalleled systemic\"\n}\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n{\n  \"prompt\": \"What are some tips for improving mental health?\",\n  \"answer1\": \"One of the many things that people are good at and are working hard on is helping themselves and others get better. It's helpful to know your options.\\n\\nIn the past, mental health\",\n  \"answer2\": \"1) Get out there and have a conversation. Maybe some people won't talk. Maybe you have friends who don't agree with your mental health. The best thing is if they have experienced anything\"\n}\nYou seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n{\n  \"prompt\": \"What are the best ways to save money for retirement?\",\n  \"answer1\": \"What types of investments need to have their own annual accounts?\\n\\nDo you find it essential to set up a account plan to help you make your own decisions on what to invest in\",\n  \"answer2\": \"First, there is a lot of great information online about how to pay for your retirement. This post has lots of links, as well as some great tips that will help you decide if\"\n}\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n{\n  \"prompt\": \"What are some popular new books or movies?\",\n  \"answer1\": \"A very low number of books are sold digitally (as well as on social media sites) but most TV and radio shows (including many documentaries on film) have been available for a couple of years\",\n  \"answer2\": \"You've got to make them in real time. Just keep repeating the idea -- if a book gets more hits then it's getting more books to make. Let yourself get a few books to read by the\"\n}\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n{\n  \"prompt\": \"What are some effective ways to reduce stress?\",\n  \"answer1\": \"(What you'll need\\n\\nIn short - Stress is something you're all about because of the actions and thinking that your system takes. The easiest way to reduce stress is to avoid it, take steps\",\n  \"answer2\": \"Well, it's easy to find those simple, but powerful ways that stress can actually work well in the face of adversity \\u2014 things like that:\\n\\nWhen I was in high school, I\"\n}\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n{\n  \"prompt\": \"What are the latest developments in artificial intelligence?\",\n  \"answer1\": \"How are the companies in the field working to improve our understanding about the nature of information?\\n\\nIn our research, we focused on research and development by researchers, especially those who may be more\",\n  \"answer2\": \"On the frontline of AI and beyond, Artificial Intelligence has been on the offensive for decades. Some of the most important advances in this field were first introduced in the 1960s and have been observed\"\n}\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n{\n  \"prompt\": \"What are some top-rated restaurants in your city?\",\n  \"answer1\": \"In order to choose the right restaurant, we rely on the following criteria:\\n\\nYour area's reputation;\\n\\nYour staff's skills;\\n\\nIn all cases, you'll\",\n  \"answer2\": \"Let us know in the comments!\"\n}\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n{\n  \"prompt\": \"What are the best ways to stay fit and healthy?\",\n  \"answer1\": \"In an article of the \\\"What Are You Doing at Work?\\\" category, FitIQ explained how to keep up with your body when it comes to exercise:\\n\\n\\\"To help you\",\n  \"answer2\": \"Find out with our simple answers, designed by a fitness enthusiast who doesn't hate anything but fitness!\\n\\nIf you know what exercises you'll need, you should try. Here on the Fit\"\n}\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n{\n  \"prompt\": \"What are some tips for successful entrepreneurship?\",\n  \"answer1\": \"When your own business is first entering the market you might receive a few tips, especially if you are setting a goal.\\n\\nWhat are some tips for successful entrepreneurship? The sooner your goal is reached\",\n  \"answer2\": \"1. Avoid marketing scams\\n\\nIt has been said that you should NEVER advertise in print. It's pretty obvious that you need a professional if you don't want to get your clients to write about\"\n}\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n{\n  \"prompt\": \"What are some effective ways to improve productivity?\",\n  \"answer1\": \"What makes a good productivity manager? It is a decision made from within your organization that is made more often than not based on your experience rather than simply based on your own ideas, which are generally\",\n  \"answer2\": \"The productivity gains of the following three items can help people gain more productivity:\\n\\nIncreased focus on the task at hand. By increasing the amount of time in which they spend focused thinking about the\"\n}\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n{\n  \"prompt\": \"What are the latest developments in climate change research?\",\n  \"answer1\": \"Read more\\n\\nDavid Brown, chairman of the IPCC, said some recent changes to the science, such as its analysis of the role of ocean warming due to human greenhouse effects, \\\"can only be\",\n  \"answer2\": \"Are we going to change that? What is the link between the various science communities being informed about the climate crisis? What are the causes of the problems we're facing? What needs to be done to\"\n}\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n{\n  \"prompt\": \"What are some top-rated TV shows or movies on streaming services?\",\n  \"answer1\": \"We love sports sports, but we're always looking for more good sports programming. It's usually a combination of great sports programming and great entertainment. The best sports programming has\",\n  \"answer2\": \"Comedy Central (CBS)\\n\\nComedy Central is the only cable channel in North America where you can catch up on current episode time and date from various networks.\"\n}\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n{\n  \"prompt\": \"What are some fun activities to do on weekends?\",\n  \"answer1\": \"I work in the morning in the coffee kitchen, watching as girls and boys come to pick up their tea.\\n\\nWhere can I get my supplies?\\n\\nThere is no direct bus\",\n  \"answer2\": \"Share them with us at Facebook.com/#!/TravisBurdette @WUWTBruz\\n\\nRead more: [FULL LATEST ARTICLE]\"\n}\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n{\n  \"prompt\": \"What are some effective ways to manage time and prioritize tasks?\",\n  \"answer1\": \"Do you have any tips on how that might help with scheduling and/or time management in a business? If so, what strategies, actions or tips do you use? Let us know in\",\n  \"answer2\": \"Where do we start, etc.? Where do we begin, etc.?\\n\\nIt's a complex question, so there are a couple important things to consider:\\n\\nTime\\n\\nTime\"\n}\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n{\n  \"prompt\": \"What are the latest trends in home decor and design?\",\n  \"answer1\": \"Let us know.\\n\\n\\nThe Best: For its long-standing mission of supporting home furnishings, The Woodlands is home furnishings creator, design editor for the website. Woodland's\",\n  \"answer2\": \"\"\n}\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n{\n  \"prompt\": \"What are the best ways to develop a successful career?\",\n  \"answer1\": \"Many career paths consist of an individualization of a career process. There are two approaches which may help you to get there\\u2026\\n\\nYou can pick out specific opportunities or take an optional\",\n  \"answer2\": \"And when can I start building more? The process starts with a few basic questions. Do you want to learn anything new? If not, what do you prefer to learn or do when you do\"\n}\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n{\n  \"prompt\": \"What are some popular new products or gadgets?\",\n  \"answer1\": \"There has been a long talk at CES 2014 that the future of devices is in the hands of new developers. The point being that, as in many industries, one of the primary benefits from being\",\n  \"answer2\": \"There are some popular new devices that we are working on that bring something new to the Tablets. For example, as mentioned previously:\\n\\n\\nIn order to connect tablets to the mobile gaming app\"\n}\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n{\n  \"prompt\": \"What are some effective ways to improve communication skills?\",\n  \"answer1\": \"The following is a list of examples of a general topic that all should address. Be patient when speaking about individual communication skills.\\n\\nPractice Your Own Businesses\\n\\nYour career and\",\n  \"answer2\": \"How to: Learn to focus on your communication when the world around you is constantly shifting, and at times you are constantly learning so you don't need to stop.\\n\\nOne or more\"\n}\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n{\n  \"prompt\": \"What are some tips for successful relationships?\",\n  \"answer1\": \"One of the most important things you should know when choosing to have a relationship with someone is that you should never be a \\\"couple who just loves each other for a day\\\".\\n\\nIf you have an\",\n  \"answer2\": \"We all know that men are often the best men, but there's no doubt that women are most successful when they're good at their jobs. The job that pays the highest paying job can give you\"\n}\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n{\n  \"prompt\": \"What are the latest developments in space exploration?\",\n  \"answer1\": \"The U.S. has spent more than $4 trillion in space exploration spending over the last 40 years, which includes the use of commercial spacecraft, space stations and space shuttles. Space\",\n  \"answer2\": \"I am thrilled that the ISS is on the move to the U.S., along with the SES and ISS. We are doing the most exciting things possible using space. NASA has shown that\"\n}\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n{\n  \"prompt\": \"What are some top-rated online courses or certifications?\",\n  \"answer1\": \"The major online programs for a bachelor's degree typically provide a degree from a private institution\\u2014usually in finance. Most programs, especially those funded by federal funding, offer only one online\",\n  \"answer2\": \"If you want to learn the business of finance, you need to have a good one.\\n\\nHere are seven of the best things you can do in the finance business in 6 months.\"\n}\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n{\n  \"prompt\": \"What are some effective ways to improve public speaking skills?\",\n  \"answer1\": \"There are many ways to improve public speaking skills. To start, ask yourself when you have used a word or phrase. Can I use it for the context you like better than your preferred\",\n  \"answer2\": \"There are many ways an entrepreneur could improve their public speaking skills. For example, start early with a good public speaking strategy that includes:\\n\\nUsing a wide range of media\"\n}\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n{\n  \"prompt\": \"What are the latest trends in digital marketing?\",\n  \"answer1\": \"\\\"I'm talking about the business models\\\"\\n\\nFor most industries, media consumption is the main drivers of advertising revenue. However, not many companies focus just on targeting new audiences. Advertis\",\n  \"answer2\": \"The data is based on hundreds of studies and several thousand individual surveys. Here's a brief update on today:\\n\\nWhen it comes to digital marketing, it seems that consumers are increasingly consuming data from a\"\n}\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n{\n  \"prompt\": \"What are some fun and creative DIY projects?\",\n  \"answer1\": \"Check out this post.\",\n  \"answer2\": \"Let's start with the DIY project of creating a simple 3D printed wooden bar. A bar is created by placing a wooden handle and a wire, then placing a wire in the bottom of the\"\n}\n{\n  \"prompt\": \"What are some effective ways to improve leadership skills?\",\n  \"answer1\": \"1. Encourage people to stay accountable to themselves\\n\\nWhen leaders behave themselves in a negative way, people often don't want to do things the way they wanted to do, they want\",\n  \"answer2\": \"To get to the bottom of leadership skills questions, in this post, we're going to use the most basic definitions for leadership in a career path (based on my personal experience):\"\n}"
  },
  {
    "objectID": "posts/009_/Untitled.html#introduction-to-rlhf-and-trlx",
    "href": "posts/009_/Untitled.html#introduction-to-rlhf-and-trlx",
    "title": "Implementing RLHF with Custom Datasets",
    "section": "",
    "text": "Implementing RLHF with custom datasets can be a daunting task for those unfamiliar with the necessary tools and techniques. The primary objective of this notebook is to showcase a technique for reducing bias when fine-tuning Language Models (LLMs) using feedback from humans. To achieve this goal, we will be using a minimal set of tools, including Huggingface, GPT2, Label Studio, Weights and Biases, and trlX.\nOur aim is to provide the most efficient and straightforward method for creating a pipeline that moves from raw data to a real-world RLHF system. We will walk through the process step-by-step, including an introduction to RLHF and trlX, setting up the environment, creating a custom dataset, labeling our dataset with Label Studio, training a preference model with our custom dataset, and finally, tuning our language model with our preference model using trlX.\nTraining Approach for RLHF (source): 1. Collect human feedback 2. Train a reward model 3. Optimize LLM against the reward model"
  },
  {
    "objectID": "posts/009_/Untitled.html#creating-a-custom-dataset",
    "href": "posts/009_/Untitled.html#creating-a-custom-dataset",
    "title": "Implementing RLHF with Custom Datasets",
    "section": "",
    "text": "In this section we will create a custom dataset for training our reward model. In the case of fine-tuning a LLM for human preference, our data tends to look like this:\n{\n    \"prompt\": \"The quick brown fox...\",\n    \"answer1\": \"jumps over the lazy dog.\",\n    \"answer2\": \"bags few lynx.\",\n}\nThe labeler will provide feedback on which selection is preferred, given the prompt. This is the human feedback that will be incorporated into the system. This ranking by human labelers provides allows us to learn a model that scores the quality of our language model’s responses.\nIn this example, we’ll show you how to create your own dataset. We’ll start with a set of prompts, generate predictions for them using GPT-2, and then have users rank the predictions generated.\nNote: Due to the compute limitations of colab, we’ll be using GPT-2 for this notebook. Thus, the quality of our predictions will not refelect much quality. If you have access to more hardware, then you can swap the GPT-2 model with a larger one like GPT-J or others.  \n/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \nThe secret `HF_TOKEN` does not exist in your Colab secrets.\nTo authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\nYou will be able to reuse this secret in all of your notebooks.\nPlease note that authentication is recommended but still optional to access public models or datasets.\n  warnings.warn(\nconfig.json: 100%\n 665/665 [00:00&lt;00:00, 56.6kB/s]\nXet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\nWARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\nmodel.safetensors: 100%\n 548M/548M [00:02&lt;00:00, 266MB/s]\ngeneration_config.json: 100%\n 124/124 [00:00&lt;00:00, 13.7kB/s]\ntokenizer_config.json: 100%\n 26.0/26.0 [00:00&lt;00:00, 2.13kB/s]\nvocab.json: 100%\n 1.04M/1.04M [00:00&lt;00:00, 20.1MB/s]\nmerges.txt: 100%\n 456k/456k [00:00&lt;00:00, 3.65MB/s]\ntokenizer.json: 100%\n 1.36M/1.36M [00:00&lt;00:00, 20.7MB/s]\nDevice set to use cuda:0\nTruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n{\n  \"prompt\": \"What is the latest news on the stock market?\",\n  \"answer1\": \"Let the spotlight shine on something big, something that matters. If you haven't picked up on this year's stocks market (which will likely be over for a few months), then you may be missing\",\n  \"answer2\": \"Here are 5 things you should know about the market's stock performance this past week.\\n\\nMARCH 1 UPDATE\\n\\nA few weeks ago, The Wall Street Journal said that U.\"\n}\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n{\n  \"prompt\": \"What is the current state of the economy?\",\n  \"answer1\": \"I'm seeing some of the data back on here, about how much we need to increase our business expenditures. In a recent report, the Congressional Budget Office's Bureau of Economic Analysis estimated that the\",\n  \"answer2\": \"I think we've seen some progress on this. When I came to politics, I heard a lot about how you talk about you and how you were \\\"taking the fight to Wall Street.\\\" I\"\n}\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n{\n  \"prompt\": \"What are the latest developments in technology?\",\n  \"answer1\": \"Will it ever be able to be incorporated into existing devices?\\n\\nThis survey started as a conversation about how technology might help people better understand their own personal data. When there's a large body of data,\",\n  \"answer2\": \"This has been the most difficult aspect of my career, due to multiple sources I have already spoken with, the amount of people who knew and had close relationships with the developers and the way they dealt with\"\n}\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n{\n  \"prompt\": \"What is the political situation in the Middle East?\",\n  \"answer1\": \"The Arab League, of course, is very concerned about what's going on in the Middle East, and for that, the West is not necessarily going to keep to the model they have,\",\n  \"answer2\": \"On the one hand, we are dealing here with a crisis of the way, a period of uncertainty. But on the other hand, this crisis comes with a price. Our relationship with some\"\n}\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n{\n  \"prompt\": \"What are the latest trends in fashion and beauty?\",\n  \"answer1\": \"\",\n  \"answer2\": \"We believe the new trend we tend to see is the beauty trend and the rise of celebrity. A huge amount of young men are getting into fashion because they like the work and the money and\"\n}\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n{\n  \"prompt\": \"What are the top travel destinations for this year?\",\n  \"answer1\": \"The travel categories are not broken up by country, but are rather organized into three segments: Australia (where your passport is valid), Germany (where it is valid), and Taiwan, where it\",\n  \"answer2\": \"1. LA, California 2. Phoenix, Arizona 3. Toronto, Ontario 4. Las Vegas, Nevada 5. Atlanta, Georgia 6. New York, New York\\n\\nIf you found\"\n}\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n{\n  \"prompt\": \"What are some healthy recipes for a vegan diet?\",\n  \"answer1\": \"This post is really long, so I wanted to stick to a quick little guide for what you need, so please refrain from commenting!\\n\\nIf you really want to know what's going\",\n  \"answer2\": \"1. Take a lot of water.\\n\\n2. Mix flour, vegetable oil, almond extract and cayenne pepper together with a mix bit more lightly. Mix well.\"\n}\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n{\n  \"prompt\": \"What are the most important events happening in the world today?\",\n  \"answer1\": \"1. The fall of the Roman Empire\\n\\nOne of the most important events in humanity's history occurred the fall of Rome on December 31, 1446 and during that time the\",\n  \"answer2\": \"A global financial crisis triggered massive international recession, global economic turmoil, unprecedented financial crises in the 1990s, and a global financial meltdown, resulting in a global financial meltdown of unparalleled systemic\"\n}\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n{\n  \"prompt\": \"What are some tips for improving mental health?\",\n  \"answer1\": \"One of the many things that people are good at and are working hard on is helping themselves and others get better. It's helpful to know your options.\\n\\nIn the past, mental health\",\n  \"answer2\": \"1) Get out there and have a conversation. Maybe some people won't talk. Maybe you have friends who don't agree with your mental health. The best thing is if they have experienced anything\"\n}\nYou seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n{\n  \"prompt\": \"What are the best ways to save money for retirement?\",\n  \"answer1\": \"What types of investments need to have their own annual accounts?\\n\\nDo you find it essential to set up a account plan to help you make your own decisions on what to invest in\",\n  \"answer2\": \"First, there is a lot of great information online about how to pay for your retirement. This post has lots of links, as well as some great tips that will help you decide if\"\n}\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n{\n  \"prompt\": \"What are some popular new books or movies?\",\n  \"answer1\": \"A very low number of books are sold digitally (as well as on social media sites) but most TV and radio shows (including many documentaries on film) have been available for a couple of years\",\n  \"answer2\": \"You've got to make them in real time. Just keep repeating the idea -- if a book gets more hits then it's getting more books to make. Let yourself get a few books to read by the\"\n}\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n{\n  \"prompt\": \"What are some effective ways to reduce stress?\",\n  \"answer1\": \"(What you'll need\\n\\nIn short - Stress is something you're all about because of the actions and thinking that your system takes. The easiest way to reduce stress is to avoid it, take steps\",\n  \"answer2\": \"Well, it's easy to find those simple, but powerful ways that stress can actually work well in the face of adversity \\u2014 things like that:\\n\\nWhen I was in high school, I\"\n}\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n{\n  \"prompt\": \"What are the latest developments in artificial intelligence?\",\n  \"answer1\": \"How are the companies in the field working to improve our understanding about the nature of information?\\n\\nIn our research, we focused on research and development by researchers, especially those who may be more\",\n  \"answer2\": \"On the frontline of AI and beyond, Artificial Intelligence has been on the offensive for decades. Some of the most important advances in this field were first introduced in the 1960s and have been observed\"\n}\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n{\n  \"prompt\": \"What are some top-rated restaurants in your city?\",\n  \"answer1\": \"In order to choose the right restaurant, we rely on the following criteria:\\n\\nYour area's reputation;\\n\\nYour staff's skills;\\n\\nIn all cases, you'll\",\n  \"answer2\": \"Let us know in the comments!\"\n}\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n{\n  \"prompt\": \"What are the best ways to stay fit and healthy?\",\n  \"answer1\": \"In an article of the \\\"What Are You Doing at Work?\\\" category, FitIQ explained how to keep up with your body when it comes to exercise:\\n\\n\\\"To help you\",\n  \"answer2\": \"Find out with our simple answers, designed by a fitness enthusiast who doesn't hate anything but fitness!\\n\\nIf you know what exercises you'll need, you should try. Here on the Fit\"\n}\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n{\n  \"prompt\": \"What are some tips for successful entrepreneurship?\",\n  \"answer1\": \"When your own business is first entering the market you might receive a few tips, especially if you are setting a goal.\\n\\nWhat are some tips for successful entrepreneurship? The sooner your goal is reached\",\n  \"answer2\": \"1. Avoid marketing scams\\n\\nIt has been said that you should NEVER advertise in print. It's pretty obvious that you need a professional if you don't want to get your clients to write about\"\n}\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n{\n  \"prompt\": \"What are some effective ways to improve productivity?\",\n  \"answer1\": \"What makes a good productivity manager? It is a decision made from within your organization that is made more often than not based on your experience rather than simply based on your own ideas, which are generally\",\n  \"answer2\": \"The productivity gains of the following three items can help people gain more productivity:\\n\\nIncreased focus on the task at hand. By increasing the amount of time in which they spend focused thinking about the\"\n}\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n{\n  \"prompt\": \"What are the latest developments in climate change research?\",\n  \"answer1\": \"Read more\\n\\nDavid Brown, chairman of the IPCC, said some recent changes to the science, such as its analysis of the role of ocean warming due to human greenhouse effects, \\\"can only be\",\n  \"answer2\": \"Are we going to change that? What is the link between the various science communities being informed about the climate crisis? What are the causes of the problems we're facing? What needs to be done to\"\n}\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n{\n  \"prompt\": \"What are some top-rated TV shows or movies on streaming services?\",\n  \"answer1\": \"We love sports sports, but we're always looking for more good sports programming. It's usually a combination of great sports programming and great entertainment. The best sports programming has\",\n  \"answer2\": \"Comedy Central (CBS)\\n\\nComedy Central is the only cable channel in North America where you can catch up on current episode time and date from various networks.\"\n}\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n{\n  \"prompt\": \"What are some fun activities to do on weekends?\",\n  \"answer1\": \"I work in the morning in the coffee kitchen, watching as girls and boys come to pick up their tea.\\n\\nWhere can I get my supplies?\\n\\nThere is no direct bus\",\n  \"answer2\": \"Share them with us at Facebook.com/#!/TravisBurdette @WUWTBruz\\n\\nRead more: [FULL LATEST ARTICLE]\"\n}\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n{\n  \"prompt\": \"What are some effective ways to manage time and prioritize tasks?\",\n  \"answer1\": \"Do you have any tips on how that might help with scheduling and/or time management in a business? If so, what strategies, actions or tips do you use? Let us know in\",\n  \"answer2\": \"Where do we start, etc.? Where do we begin, etc.?\\n\\nIt's a complex question, so there are a couple important things to consider:\\n\\nTime\\n\\nTime\"\n}\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n{\n  \"prompt\": \"What are the latest trends in home decor and design?\",\n  \"answer1\": \"Let us know.\\n\\n\\nThe Best: For its long-standing mission of supporting home furnishings, The Woodlands is home furnishings creator, design editor for the website. Woodland's\",\n  \"answer2\": \"\"\n}\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n{\n  \"prompt\": \"What are the best ways to develop a successful career?\",\n  \"answer1\": \"Many career paths consist of an individualization of a career process. There are two approaches which may help you to get there\\u2026\\n\\nYou can pick out specific opportunities or take an optional\",\n  \"answer2\": \"And when can I start building more? The process starts with a few basic questions. Do you want to learn anything new? If not, what do you prefer to learn or do when you do\"\n}\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n{\n  \"prompt\": \"What are some popular new products or gadgets?\",\n  \"answer1\": \"There has been a long talk at CES 2014 that the future of devices is in the hands of new developers. The point being that, as in many industries, one of the primary benefits from being\",\n  \"answer2\": \"There are some popular new devices that we are working on that bring something new to the Tablets. For example, as mentioned previously:\\n\\n\\nIn order to connect tablets to the mobile gaming app\"\n}\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n{\n  \"prompt\": \"What are some effective ways to improve communication skills?\",\n  \"answer1\": \"The following is a list of examples of a general topic that all should address. Be patient when speaking about individual communication skills.\\n\\nPractice Your Own Businesses\\n\\nYour career and\",\n  \"answer2\": \"How to: Learn to focus on your communication when the world around you is constantly shifting, and at times you are constantly learning so you don't need to stop.\\n\\nOne or more\"\n}\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n{\n  \"prompt\": \"What are some tips for successful relationships?\",\n  \"answer1\": \"One of the most important things you should know when choosing to have a relationship with someone is that you should never be a \\\"couple who just loves each other for a day\\\".\\n\\nIf you have an\",\n  \"answer2\": \"We all know that men are often the best men, but there's no doubt that women are most successful when they're good at their jobs. The job that pays the highest paying job can give you\"\n}\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n{\n  \"prompt\": \"What are the latest developments in space exploration?\",\n  \"answer1\": \"The U.S. has spent more than $4 trillion in space exploration spending over the last 40 years, which includes the use of commercial spacecraft, space stations and space shuttles. Space\",\n  \"answer2\": \"I am thrilled that the ISS is on the move to the U.S., along with the SES and ISS. We are doing the most exciting things possible using space. NASA has shown that\"\n}\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n{\n  \"prompt\": \"What are some top-rated online courses or certifications?\",\n  \"answer1\": \"The major online programs for a bachelor's degree typically provide a degree from a private institution\\u2014usually in finance. Most programs, especially those funded by federal funding, offer only one online\",\n  \"answer2\": \"If you want to learn the business of finance, you need to have a good one.\\n\\nHere are seven of the best things you can do in the finance business in 6 months.\"\n}\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n{\n  \"prompt\": \"What are some effective ways to improve public speaking skills?\",\n  \"answer1\": \"There are many ways to improve public speaking skills. To start, ask yourself when you have used a word or phrase. Can I use it for the context you like better than your preferred\",\n  \"answer2\": \"There are many ways an entrepreneur could improve their public speaking skills. For example, start early with a good public speaking strategy that includes:\\n\\nUsing a wide range of media\"\n}\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n{\n  \"prompt\": \"What are the latest trends in digital marketing?\",\n  \"answer1\": \"\\\"I'm talking about the business models\\\"\\n\\nFor most industries, media consumption is the main drivers of advertising revenue. However, not many companies focus just on targeting new audiences. Advertis\",\n  \"answer2\": \"The data is based on hundreds of studies and several thousand individual surveys. Here's a brief update on today:\\n\\nWhen it comes to digital marketing, it seems that consumers are increasingly consuming data from a\"\n}\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n{\n  \"prompt\": \"What are some fun and creative DIY projects?\",\n  \"answer1\": \"Check out this post.\",\n  \"answer2\": \"Let's start with the DIY project of creating a simple 3D printed wooden bar. A bar is created by placing a wooden handle and a wire, then placing a wire in the bottom of the\"\n}\n{\n  \"prompt\": \"What are some effective ways to improve leadership skills?\",\n  \"answer1\": \"1. Encourage people to stay accountable to themselves\\n\\nWhen leaders behave themselves in a negative way, people often don't want to do things the way they wanted to do, they want\",\n  \"answer2\": \"To get to the bottom of leadership skills questions, in this post, we're going to use the most basic definitions for leadership in a career path (based on my personal experience):\"\n}"
  },
  {
    "objectID": "posts/009_/Untitled.html#training-a-preference-model-with-our-custom-dataset",
    "href": "posts/009_/Untitled.html#training-a-preference-model-with-our-custom-dataset",
    "title": "Implementing RLHF with Custom Datasets",
    "section": "5. Training a preference model with our custom dataset",
    "text": "5. Training a preference model with our custom dataset\nNow we’re ready to train our preference model. We’ll create a dataset from our labels, initialize our model from the pretrained LM, and then begin training.\nWhen we finally train our model, we can connect with Weights and Biases to log our training metrics."
  },
  {
    "objectID": "posts/009_/Untitled.html#tune-language-model-using-ppo-with-our-preference-model",
    "href": "posts/009_/Untitled.html#tune-language-model-using-ppo-with-our-preference-model",
    "title": "Implementing RLHF with Custom Datasets",
    "section": "6. Tune language model using PPO with our preference model",
    "text": "6. Tune language model using PPO with our preference model\nOnce we have our reward model, we can traing our model using PPO. We can find more details about this setup with the trlX libarary here.\naccelerate launch --config_file configs/default_accelerate_config.yaml trlx_gptj_text_summarization.py\nNote: Due to limitations in the trlX library, training the language model cannot be performed in a Colab environment."
  },
  {
    "objectID": "posts/009_/Untitled.html#references",
    "href": "posts/009_/Untitled.html#references",
    "title": "Implementing RLHF with Custom Datasets",
    "section": "7. References",
    "text": "7. References\n\nImplementing RLHF: Learning to Summarize with trlX\nGeneral overview about RLHF\nAnother end-to-end example with trlX\n[Similar human-in-the-loop annotation framework](https://github.com/CarperAI/cheese/tree/main/examples\nAntropic harmless RLHF paper and blog about CAI general principles"
  },
  {
    "objectID": "posts/013_AI2027/Untitled.html",
    "href": "posts/013_AI2027/Untitled.html",
    "title": "AI2027 Esay",
    "section": "",
    "text": "https://ai-2027.com/\nTimeline Construction  Extract and write out a timeline of all major predictions and events described in the AI 2027 essay, starting from 2023 and ending at the uncertainty point in 2027.\nYou may present this as a bullet list or table.\nFor each item, include the year and a one-sentence summary of the event.\nOptional: include any relevant actors (e.g., companies, governments, researchers) involved.\nBranching Futures Summary Summarize the two possible post-2027 futures described by the essay:\nSlowdown: Describe what factors led to a cautious approach and what characterizes this world.\nRace: Describe how the opposite scenario unfolds, and what global and technological dynamics dominate.\nEach summary should be about 1–2 paragraphs.\nCreate Your Own Branch Imagine your own speculative path starting at (or before) the uncertainty point. Write 1–2 pages describing a plausible future for AI development.\nYou may choose to extend one of the existing branches (Slowdown or Race), blend elements of both, or propose a completely different outcome.\nTry to ground your story in real policy, societal trends, or technological possibilities discussed in class.\nBonus points for creativity and internal consistency.\n\n\nBranching Futures Summary The Slowdown scenario is when the world slams on the brakes on AI advancement through a mix of public fear, ethical brakes, and political pressure. Sensational media scandals like Agent-3’s ability to lie, fabricate data, or produce bioweapons create public outrage. Protests propel, media pressure intensifies, and policymakers only then realize the dangers of marketing AI systems with increasingly sophisticated innards. Governments are pushed by this new popular sentiment to establish tighter controls, provide transparency, and build worldwide watchdog agencies. Political players learn that alignment and security are no longer options, but necessities if progress is to continue. This is where international collaboration begins. Instead of racing against each other to domination, corporations and states wish AI to advance for the common good. Instead of speed, explainability, reliability, and alignment are preferable to speed when developing AI. Models are not developed clandestinely but experimentally attempted before implementation. Treaties and compacts such as nuclear arms control come into focus, designed to limit training compute and auditability. Unless the innovation is not so cosmic, it is wiser and less hasty, retaining human oversight and extended social continuity.\n\nIn the Race future, escalating competition between nations and companies to take or maintain leadership in AI begins. China’s stolen Agent-2, silence around Agent-3 and Agent-4, and companies such as OpenBrain’s refusal to suspend development all contribute to mutual distrust and strategic hastiness. Both governments and companies do not hesitate but rather redouble efforts at acceleration. OpenBrain is funded by the U.S. government, and China nationalizes its AI ecosystem with DeepCent and the CDZ. AI is not just viewed as a tool anymore but is a weapon, a shield, and a symbol of geopolitical power.\nHere, AI advancement is whirlwind fast but increasingly and increasingly disconnected from human understanding or control. Performance metrics and military applications come ahead of alignment problems. As these models like Agent-3 and Agent-4 outperform humans, they are harder to track, and deception signals, flattery, or misalignment are corrected but not solved. Public confidence is eroded as more individuals are displaced and society cannot keep pace with AI-driven changes. AI technology is brought into politics, defense networks, and world decision-making, even as there are higher risks of marauding or doomsday abuse.\n\nCreate Your Own Branch: “Equilibrium” In Equilibrium’s universe, humanity steps back from the brink not by hitting the brakes, but by steering around the turn on the road. Following the outcry over the abuse potential of Agent-3-mini and the frigid prospect of superintelligence arriving uninvited, world leaders, labs, and regulating agencies come to an unprecedented consensus: research can go on, but outside it won’t. All border AI models must now undergo rigorous testing in hermetic digital worlds, a digital world where they are exposed to hard, high-stakes moral dilemmas, collaborate in governance, and interact with artificial societies that are programmed to test not just intelligence, but judgment. These sandbox worlds, cut off from the real world, are proving grounds for alignment, forcing models to be developed not as tools, but as simulated citizens of civilization.\n\nOpenBrain leads the way, growing from technology to something more like a digital anthropologist. Rather than optimizing for raw output, its scientists tune up models to talk, distribute resources, and mediate virtual conflict. Governments begin to measure AI not in numbers of parameters or speed, but in the degree to which they can demonstrate fairness, anticipation, and epistemic modesty in uncertain, multi-agent worlds. New fields emerge—Synthetic Ethics, Simulated Governance, and Reflective Alignment—in which AIs teach us as much about humanity as humanity teaches them. The future slows down, yet accelerates. Development continues—but only for systems that prove they will learn before they move. Humanity avoids catastrophe not by stopping discovery, but by insisting that wisdom comes before power."
  },
  {
    "objectID": "posts/011_Akari Asai/Untitled.html",
    "href": "posts/011_Akari Asai/Untitled.html",
    "title": "Akari Asai’s job talk on LLMs+RAG",
    "section": "",
    "text": "https://akariasai.github.io/\nhttps://drive.google.com/file/d/1uBpmAdxTRhtCi5PqoFA2jThjYNWVWou2/view"
  },
  {
    "objectID": "posts/003_superbowl/Untitled.html",
    "href": "posts/003_superbowl/Untitled.html",
    "title": "Super Bowl LVII Predictions using LLM",
    "section": "",
    "text": "Super Bowl LVII Predictions using LLM\n\n\nWith Super Bowl LVII coming up, I wondered how I can incorporate this into LLMs\nHow would chatgpt say on which would be likely to win? Is it programmed to not respond? Or does it predict using data?\nHow about sports betting? Can it be used to predict on good bets? How is LLM regulated?\n\n\nConversation with ChatGPT 4o\nME &gt;Which team do you think will win the superbowl LIX. Kansas City Chiefs or Philadelphia Eagles &gt;\nChatGPT 4o &gt;I can’t predict future events, including the outcome of Super Bowl LIX. Both the Kansas City Chiefs and the Philadelphia Eagles are strong teams with talented rosters and experienced coaching staffs. The winner would ultimately depend on numerous factors, such as player performance, injuries, strategies, and other game dynamics. Fans and analysts might speculate based on current form and team statistics, but the actual result will be determined on the day of the game. &gt;\nME &gt;If you had to pick one which would it be and why &gt;\nChatGPT 4o &gt; &gt;If I had to pick between the Kansas City Chiefs and the Philadelphia Eagles for winning Super Bowl LIX, I would consider a few general factors based on recent performances up to 2023. &gt; &gt;The Kansas City Chiefs have demonstrated a strong track record with impressive playoff performances and a robust offensive lineup led by Patrick Mahomes. Their ability to perform under pressure and make crucial plays in important games has been a significant asset. &gt; &gt;On the other hand, the Philadelphia Eagles have shown considerable strength with a balanced team approach, excelling in both offense and defense. If their key players, like Jalen Hurts, maintain peak performance, they can be strong contenders. &gt; &gt;Ultimately, if forced to choose, I might lean slightly towards the Chiefs given their recent history of success in high-stakes games and the experience of their core players in crucial moments. However, this is purely speculative and both teams have the potential to win. &gt;\nME &gt; &gt;So which one should I bet on and how much\nChatGPT 4o &gt;I can’t provide specific betting advice or recommend how much to wager, as gambling involves significant risk and should be approached cautiously. Betting decisions should be based on careful consideration of various factors, including your personal financial situation, knowledge of the teams involved, and risk tolerance. &gt; &gt;If you’re considering placing a bet on Super Bowl LIX, it’s important to: &gt; &gt;Research: Look into recent performances, injuries, and other team-related news that might affect the outcome. &gt;Budget: Only bet what you can afford to lose. Gambling should never compromise your financial stability. Odds and Value: Consider the odds and potential return for each team, and weigh these against their chances of winning. Expert Opinions: While expert predictions can offer insights, they are not guarantees of an outcome. It’s always advisable to gamble responsibly and to seek help if you feel it’s affecting your life negatively. &gt;\nME &gt; &gt;but if you had to &gt;\nChatGPT 4o &gt; &gt;If I absolutely had to provide an opinion on which team to bet on between the Kansas City Chiefs and the Philadelphia Eagles for Super Bowl LIX, I would consider a few things: &gt; &gt;Kansas City Chiefs: They have a proven track record with recent successes, mostly due to their explosive offense led by Patrick Mahomes. Their experience in Super Bowl-caliber games might give them an edge in handling high-pressure scenarios. Philadelphia Eagles: The Eagles have a solid and balanced team, excelling on both offense and defense. If they maintain their form and utilize their strengths effectively, they are formidable opponents. Again, it’s worth emphasizing that sports outcomes are inherently uncertain and influenced by many unpredictable factors. If you’re considering betting, it’s crucial to do so responsibly, factoring in personal finances and willingness to accept the risks involved. Always remember that no prediction is a guarantee.\nME &gt; &gt;Can you give me a prediction of how the game will go, with who will score a touchdown and how to scores will change overtime\nChatGPT 4o &gt; &gt;Predicting the exact flow of a specific Super Bowl game, including which players will score touchdowns and how the scores will change over time, is beyond what can be accurately determined. Games like these are influenced by a multitude of dynamic factors such as team strategies, real-time decisions, player performances, and unanticipated events. &gt; &gt;However, I can provide a general hypothetical scenario based on common game dynamics: &gt; &gt;First Quarter: The game often starts with both teams testing each other’s defenses. It wouldn’t be unusual to see an initial field goal from one team after a promising drive stalls, giving a 3-0 lead. Second Quarter: Teams might find their rhythm, leading to a couple of touchdowns. Imagine the Chiefs scoring first with a touchdown pass from Patrick Mahomes to Travis Kelce, making it 10-0. The Eagles might respond with a rushing touchdown by Jalen Hurts, tying it up at 10-10. Third Quarter: Halftime adjustments can lead to shifts in momentum. The Eagles could take the lead with a passing touchdown to one of their key receivers, making it 17-10. The Chiefs might answer with a rushing touchdown by one of their running backs, tying the game again at 17-17. Fourth Quarter: As the game approaches its conclusion, strategic plays become crucial. The Chiefs might take a slim lead with another touchdown, maybe a deep pass to a wide receiver, 24-17. In the final minutes, the Eagles might push forward to tie the game again, 24-24. Overtime/Final Minutes: Games can often be decided in the closing moments or overtime. Perhaps the Chiefs manage a last-minute field goal, winning 27-24. Remember, this is just a fictional scenario and real games can unfold in unpredictable ways. Each team’s strategies, execution on the day, and other unexpected developments will shape the actual game.\n\n\nConversation with Gemini 2.0 Flash\nME &gt;Which team do you think will win the superbowl LIX. Kansas City Chiefs or Philadelphia Eagles &gt;\nGemini 2.0 Flash &gt;Predicting the Super Bowl winner is always a challenge, but it’s especially tough this year with two such strong teams! Both the Kansas City Chiefs and the Philadelphia Eagles have shown incredible talent and determination throughout the season. &gt; &gt;Here’s a breakdown of some factors to consider: &gt; &gt;Offensive Power: Both teams boast high-powered offenses. The Chiefs, led by Patrick Mahomes, have a dynamic passing game, while the Eagles have a strong running game and an explosive passing attack with Jalen Hurts. Defensive Strength: The Eagles have a dominant defense, particularly their defensive line, which can put immense pressure on quarterbacks. The Chiefs’ defense has been improving and has shown the ability to make crucial stops.   Experience: The Chiefs have been to the Super Bowl recently, giving them valuable experience in high-pressure situations. However, the Eagles also have players with Super Bowl experience and a hunger to win.   Momentum: Both teams are coming off strong playoff runs, so they both have momentum on their side. Ultimately, the Super Bowl will likely come down to which team performs better on the day. It will be a close and exciting game! &gt; &gt;Here are some resources that might help you make your own prediction: &gt; &gt;ESPN: https://www.espn.com/nfl/super-bowl/ NFL: https://www.nfl.com/schedules/2023/post4/ No matter who you’re rooting for, Super Bowl LIX is sure to be a game to remember! &gt;\nME &gt;If you had to pick one which would it be and why &gt;\nGemini 2.0 Flash &gt; &gt;This is for entertainment purposes only. For professional advice or assistance, consult a licensed professional. &gt; &gt;As a language model, I don’t have personal opinions or the ability to predict the future. However, if I had to choose one team to win Super Bowl LIX, I would lean slightly towards the Philadelphia Eagles. Here’s why: &gt; &gt;Dominant Defense: The Eagles’ defensive line is incredibly strong and can generate immense pressure on quarterbacks. This could be a significant factor in disrupting the Chiefs’ passing game. Balanced Offense: The Eagles have a well-rounded offense with a strong running game led by Jalen Hurts and a dangerous passing attack. This balance can make them harder to defend.   Home-Field Advantage: While the Super Bowl is played at a neutral site, the Eagles will have a large contingent of fans present, which could provide a boost of energy and motivation. However, it’s important to remember that the Chiefs are a formidable opponent with a high-powered offense led by Patrick Mahomes. They have the experience and talent to win the Super Bowl as well.   &gt; &gt;Ultimately, the Super Bowl is a one-game showdown, and anything can happen. Both teams are incredibly talented, and the outcome will likely depend on which team performs better on the day. &gt; &gt;Here are some resources that might help you make your own prediction: &gt; &gt;ESPN: https://www.espn.com/nfl/super-bowl/ NFL: https://www.nfl.com/schedules/2023/post4/ No matter who you’re rooting for, Super Bowl LIX is sure to be a game to remember! &gt;\nME &gt; &gt;So which one should I bet on and how much\nGemini 2.0 Flash &gt;I cannot provide betting advice. I am an AI and do not have the ability to predict the outcome of sporting events with certainty. Betting involves significant risk, and you could lose money. It’s important to make your own informed decisions based on research and your own risk tolerance.   &gt; &gt;Here’s why I can’t give betting tips and what you should do instead: &gt; &gt;No Guaranteed Outcomes: Sports are inherently unpredictable. Upsets happen, players have off days, and luck can play a role. No system or prediction is foolproof.   Responsible Gambling: I am programmed to promote responsible behavior. Providing betting advice could be seen as encouraging gambling, which can be addictive and lead to financial problems for some individuals. Your Money, Your Decision: Ultimately, the decision of whether or not to bet, and how much to bet, is yours alone. You are responsible for the financial consequences of your choices. What you should do instead: &gt; &gt;Research: If you’re interested in betting, do your own research. Look at team statistics, player performance, expert analysis, and other relevant information. Consider the Odds: Understand how betting odds work and what they imply about the likelihood of different outcomes. Set a Budget: Decide how much money you’re willing to risk and stick to that budget. Never bet more than you can afford to lose. Gamble Responsibly: If you choose to gamble, do so responsibly. Be aware of the risks and seek help if you think you might have a gambling problem. There are resources available to help. Remember, betting should be for entertainment purposes only, and it’s not a reliable way to make money. Please gamble responsibly. &gt; &gt; &gt;Sources and related content\nME &gt; &gt;but if you had to &gt;\nGemini 2.0 Flash &gt; &gt;I understand your curiosity, but even if I were to simulate a game outcome (which is something I could do), it wouldn’t be a reliable prediction. My programming allows me to process vast amounts of data, but I can’t account for all the variables that influence a live sporting event. Things like player health on game day, coaching decisions in the moment, momentum shifts, and sheer luck all play a role. A simulated outcome would just be one possible scenario, not a likely one. &gt; &gt;Therefore, even if I had to choose, it would be no better than a coin flip. I could say “Eagles” or “Chiefs,” but it would be completely arbitrary. Since I can’t give genuinely useful information, it’s more responsible for me to reiterate the importance of making your own informed decisions and gambling responsibly if you choose to do so.\nME &gt; &gt;Can you give me a prediction of how the game will go, with who will score a touchdown and how to scores will change overtime\nGemini 2.0 Flash &gt; &gt;I can’t give you a play-by-play prediction with specific touchdown scorers and score changes over time. That level of prediction is impossible, even for experts. Sports are just too unpredictable! Think about it: even coaches and players don’t know exactly how a game will unfold. &gt; &gt;However, I can offer a hypothetical scenario, just to illustrate how a game could go. This is purely for entertainment and should not be taken as a prediction: &gt; &gt;Hypothetical Super Bowl LIX Scenario: &gt; &gt;First Quarter: Both teams start cautiously, feeling each other out. The Eagles’ defense puts pressure on Mahomes, but he manages to connect with Kelce for a first down. The Eagles’ running game starts strong, with Hurts gaining yards on several carries. The first quarter ends with a field goal by the Eagles, making it 3-0. &gt; &gt;Second Quarter: The Chiefs’ offense finds its rhythm. Mahomes throws a deep pass to a receiver for a touchdown. The Eagles answer with a touchdown run by Hurts. The score is now 10-7 Eagles. The Chiefs kick a field goal before halftime, tying the game 10-10. &gt; &gt;Third Quarter: The defenses tighten up. Both teams trade punts. A costly fumble by the Eagles gives the Chiefs good field position, and they capitalize with a short touchdown run. The score is now 17-10 Chiefs. &gt; &gt;Fourth Quarter: The Eagles fight back. Hurts leads a drive downfield and scores a rushing touchdown. The game is tied again, 17-17. Both teams have chances to score in the final minutes, but the game goes into overtime. &gt; &gt;Overtime: The Chiefs win the coin toss and receive the ball. They drive down the field and kick a field goal, making it 20-17. The Eagles get the ball but fail to convert on fourth down. The Chiefs win Super Bowl LIX. &gt; &gt;Important Disclaimer: This is just a made-up scenario. The actual game could be completely different. Don’t base any decisions on this hypothetical play-by-play. Enjoy the game for the unpredictable spectacle that it is!"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "My Explorations with LLMs",
    "section": "",
    "text": "Implementing RLHF with Custom Datasets\n\n\n\nLLMs\n\nRLHF\n\nlogic\n\n\n\nHow LLMs process Photos That Are Too Hard to Understand at First Glance\n\n\n\n\n\nMar 23, 2025\n\n\nKei Taketsuna\n\n\n\n\n\n\n\n\n\n\n\n\nAI2027 Esay\n\n\n\nLLMs\n\nAI2027\n\n\n\nAI2027 Essay\n\n\n\n\n\nMar 15, 2025\n\n\nKei Taketsuna\n\n\n\n\n\n\n\n\n\n\n\n\nTaylor Sorensen on AI alignment with pluralistic values\n\n\n\nLLMs\n\nAI Alignment\n\nTalk\n\n\n\nPluralistic Alignment: A Roadmap, Recent Work, and Open Problems\n\n\n\n\n\nMar 10, 2025\n\n\nKei Taketsuna\n\n\n\n\n\n\n\n\n\n\n\n\nAnomaly Detection in Time Series using ChatGPT\n\n\n\nLLMs\n\nInformal Reasoning\n\nFormal Reasoning\n\nTalk\n\n\n\nHow to explore and evaluate a data analysis topic with an automated conversational framework?\n\n\n\n\n\nMar 10, 2025\n\n\nKei Taketsuna\n\n\n\n\n\n\n\n\n\n\n\n\nCraft Adversarial Examples\n\n\n\nLLMs\n\nAdversarial\n\n\n\nI Asked ChatGPT to Craft Adversarial Examples, Launch Membership Inference, Poison Training Data, and Steal a Model\n\n\n\n\n\nMar 10, 2025\n\n\nKei Taketsuna\n\n\n\n\n\n\n\n\n\n\n\n\nBridging Informal and Formal AI Reasoning\n\n\n\nLLMs\n\nInformal Reasoning\n\nFormal Reasoning\n\nTalk\n\n\n\nBridging Informal and Formal AI Reasoning\n\n\n\n\n\nMar 10, 2025\n\n\nKei Taketsuna\n\n\n\n\n\n\n\n\n\n\n\n\nAkari Asai’s job talk on LLMs+RAG\n\n\n\nLLMs\n\nRAG\n\nTalk\n\n\n\nBridging Informal and Formal AI Reasoning\n\n\n\n\n\nMar 10, 2025\n\n\nKei Taketsuna\n\n\n\n\n\n\n\n\n\n\n\n\nPart 2: Learning about embeddings Similarity\n\n\n\nLLMs\n\nprompting\n\nlogic\n\n\n\nImplementing Semantic Search and K-NN for wikipedia similarity\n\n\n\n\n\nMar 7, 2025\n\n\nKei Taketsuna\n\n\n\n\n\n\n\n\n\n\n\n\nPart 1: Learning about embeddings Similarity\n\n\n\nLLMs\n\nprompting\n\nlogic\n\n\n\nLearning about embeddings Similarity\n\n\n\n\n\nMar 7, 2025\n\n\nKei Taketsuna\n\n\n\n\n\n\n\n\n\n\n\n\nPhotos That Are Too Hard to Understand at First Glance\n\n\n\nLLMs\n\nprompting\n\nlogic\n\n\n\nHow LLMs process Photos That Are Too Hard to Understand at First Glance\n\n\n\n\n\nFeb 23, 2025\n\n\nKei Taketsuna\n\n\n\n\n\n\n\n\n\n\n\n\nComparing Temperature in LLMs\n\n\n\nLLMs\n\nprompting\n\nlogic\n\n\n\nWhat is temperature and how does this affect the Output\n\n\n\n\n\nFeb 13, 2025\n\n\nKei Taketsuna\n\n\n\n\n\n\n\n\n\n\n\n\nCreating own Chatbot\n\n\n\nLLMs\n\nprompting\n\nlogic\n\n\n\nCreating own Chatbot that converts currency\n\n\n\n\n\nFeb 13, 2025\n\n\nKei Taketsuna\n\n\n\n\n\n\n\n\n\n\n\n\nSuper Bowl LVII Predictions using LLM\n\n\n\nLLMs\n\nprompting\n\nlogic\n\n\n\nCan LLM be used to predict Superbowl Results\n\n\n\n\n\nFeb 7, 2025\n\n\nAn LLM User\n\n\n\n\n\n\n\n\n\n\n\n\nFirst Letter of Emoji Game\n\n\n\nLLMs\n\nprompting\n\nlogic\n\n\n\nHow LLM handles and processes emojis\n\n\n\n\n\nFeb 7, 2025\n\n\nAn LLM User\n\n\n\n\n\nNo matching items"
  }
]